{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r6_MmC9A4lRw",
        "outputId": "40e9926d-2669-4f4e-f05d-ded240efb45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujMb2MtyLrVQ"
      },
      "source": [
        "# exploration 14번째 과제\n",
        "@ 황한용(3기/쏘카)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdrfR8Y3L0ry"
      },
      "source": [
        "## 라이브러리 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LWLP8EFSLqqp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qC6hZWKL7x3"
      },
      "source": [
        "## 상수선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XcIjEEgnMD75"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/data/bot\" # 기본 데이터경로\n",
        "DATA_PATH = BASE_PATH + \"/ChatbotData.csv\" # 영화에 관한 사용자의 평가가 들어가있는 데이터경로"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvrvgLxw4R3T"
      },
      "source": [
        "## 함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZfUuA1x5JZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZrsV5Zf4R3T"
      },
      "source": [
        "속도의 문제로 인하여 소스코드를 변경하였다.<br>\n",
        "불용어 제거까지 적용시 늦어도 30초내외로 걸린다.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DV1kd8MPes"
      },
      "source": [
        "## 메인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7XCWajZ0XIj"
      },
      "source": [
        "### 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "iwkvcfr7MPsm",
        "outputId": "20ef3f31-5968-4400-aacd-604493a1e629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c62b86e0-a242-4a73-b56e-4a8b8cadea56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c62b86e0-a242-4a73-b56e-4a8b8cadea56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c62b86e0-a242-4a73-b56e-4a8b8cadea56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c62b86e0-a242-4a73-b56e-4a8b8cadea56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data = pd.read_csv(DATA_PATH)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXm0KjWe845_"
      },
      "source": [
        "질문컬럼인`Q`, 대답부분인`A`와 `label`으로 구성되어있다.<br>\n",
        "`label`값의 숫자는 다음과 같다.\n",
        "- 일상다반사: 0\n",
        "- 이별(부정): 1\n",
        "- 사랑(긍정): 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKtAnrjS4R3V"
      },
      "outputs": [],
      "source": [
        "orginal_data_size = len(ratings)\n",
        "ratings = ratings[ratings['ratings'] > 2]\n",
        "filtered_data_size = len(ratings)\n",
        "\n",
        "print(\n",
        "    f\"\"\"orginal_data_size: {orginal_data_size}, filtered_data_size: {filtered_data_size}\n",
        "Ratio of Remaining Data is {filtered_data_size / orginal_data_size:.2%}\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XB-Tj0o4R3V"
      },
      "source": [
        "평점 3점 이하의 데이터는 모두 drop한다.<br>\n",
        "그 후 로드시의 데이터와 filtering한 데이터의 수, filtering한 데이터의 %를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "971TB3kw845_"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv(\n",
        "    MF_Q_DATA_PATH\n",
        "    , names=MF_Q_COLS\n",
        "    , **READ_CSV_KWARGS\n",
        ")\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajtkCZfqI5ew"
      },
      "source": [
        "기사는 불용어 제거, 요약은 불용어 제거하지 않은 상태로 전처리를 하며<br>\n",
        "전처리로 인하여 인하여 생긴 빈 문자열은 제거한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqRQGXQf4R3W"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_user = ratings['user_id'].nunique()\n",
        "num_movie = movies['movie_id'].nunique()\n",
        "\n",
        "print(\"total movie: \", len(num_movie))\n",
        "print(\"total user: \", len(num_user))\n",
        "print(\"top 30 movie: \", movies.sort_values())\n",
        "\n",
        "\n",
        "csr_data = csr_matrix((\n",
        "        ratings['ratings'], (ratings['user_id'], movies['movie_id'])\n",
        "    ), shape= (num_user, num_movie)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxwqHv454R3W"
      },
      "source": [
        "유저와 영화의 유니크한 백터를 구하며 이를 사용해 `csr_matrix`를 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX-uCKCAK1FQ"
      },
      "outputs": [],
      "source": [
        "text_max_len = 60\n",
        "headlines_max_len = 8\n",
        "\n",
        "text_len = [len(s.split()) for s in data['text']]\n",
        "headlines_len = [len(s.split()) for s in data['headlines']]\n",
        "\n",
        "print(f\"텍스트의 최소 길이 : {np.min(text_len)}\")\n",
        "print(f\"텍스트의 최대 길이 : {np.max(text_len)}\")\n",
        "print(f\"텍스트의 평균 길이 : {np.mean(text_len)}\")\n",
        "print(f\"요약의 최소 길이 : {np.min(headlines_len)}\")\n",
        "print(f\"요약의 최대 길이 : {np.max(headlines_len)}\")\n",
        "print(f\"요약의 평균 길이 : {np.mean(headlines_len)}\")\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(headlines_len)\n",
        "plt.title('headlines')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('headlines')\n",
        "plt.hist(headlines_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "below_threshold_len(text_max_len, data['text'])\n",
        "below_threshold_len(headlines_max_len,  data['headlines'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9kNM2TiK1RF"
      },
      "source": [
        "기사와 요약의 최소, 최대, 평균 길이와 길이 분포를 시각화함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JuGfeZf4R3X"
      },
      "outputs": [],
      "source": [
        "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
        "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dULqibK74R3X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT7t_Wn44R3X"
      },
      "outputs": [],
      "source": [
        "data['decoder_input'] = SOS_TOKEN + \" \" + data['headlines']\n",
        "data['decoder_target'] = data['headlines'] + \" \" +EOS_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u-FrFx_4R3Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eALdl3nc4R3Y"
      },
      "outputs": [],
      "source": [
        "encoder_input = np.array(data['text']) # 인코더의 입력\n",
        "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
        "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvYtwRHX4R3Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7msDm96u4R3Y"
      },
      "outputs": [],
      "source": [
        "# index shuffle\n",
        "news_max_len = encoder_input.shape[0]\n",
        "news_valid_len = int(news_max_len * 0.2)\n",
        "\n",
        "shuffle_idx  = np.arange(news_max_len)\n",
        "np.random.shuffle(shuffle_idx)\n",
        "\n",
        "encoder_input = encoder_input[shuffle_idx]\n",
        "decoder_input = decoder_input[shuffle_idx]\n",
        "decoder_target = decoder_target[shuffle_idx]\n",
        "\n",
        "# 학습과 테스트, 점증 데이터 분리\n",
        "\n",
        "encoder_input_train = encoder_input[:-news_valid_len]\n",
        "decoder_input_train = decoder_input[:-news_valid_len]\n",
        "decoder_target_train = decoder_target[:-news_valid_len]\n",
        "\n",
        "encoder_input_test = encoder_input[-news_valid_len:]\n",
        "decoder_input_test = decoder_input[-news_valid_len:]\n",
        "decoder_target_test = decoder_target[-news_valid_len:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPVAJ5qf4R3Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbFIKeNV_L8U"
      },
      "outputs": [],
      "source": [
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGb9W_034R3Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIpFCQjt4R3Z"
      },
      "outputs": [],
      "source": [
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print(f\"단어 집합(vocabulary)의 크기 : {total_cnt}\", )\n",
        "print(f\"등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}\")\n",
        "print(f\"단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 {total_cnt - rare_cnt}\")\n",
        "print(f\"단어 집합에서 희귀 단어의 비율: {(rare_cnt / total_cnt)*100}\")\n",
        "print(f\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: {(rare_freq / total_freq)*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaZIxCdS4R3Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJGebiS44R3Z"
      },
      "outputs": [],
      "source": [
        "src_vocab = 8000\n",
        "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
        "\n",
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
        "\n",
        "# 잘 진행되었는지 샘플 출력\n",
        "print(encoder_input_train[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE66BBr_4R3Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOEMoRNG4R3Z"
      },
      "outputs": [],
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLxlqVl04R3Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3pKV0gJ4R3Z"
      },
      "outputs": [],
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print(f\"단어 집합(vocabulary)의 크기 : {total_cnt}\", )\n",
        "print(f\"등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}\")\n",
        "print(f\"단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 {total_cnt - rare_cnt}\")\n",
        "print(f\"단어 집합에서 희귀 단어의 비율: {(rare_cnt / total_cnt)*100}\")\n",
        "print(f\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: {(rare_freq / total_freq)*100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6TNQPiG4R3a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpBesiC84R3a"
      },
      "outputs": [],
      "source": [
        "tar_vocab = 2000\n",
        "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
        "\n",
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
        "\n",
        "# 잘 변환되었는지 확인\n",
        "print('input')\n",
        "print('input ',decoder_input_train[:5])\n",
        "print('target')\n",
        "print('decoder ',decoder_target_train[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n9i9WcC4R3a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dPDvpJ04R3a"
      },
      "outputs": [],
      "source": [
        "drop_train = set([index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1])\n",
        "drop_test = set([index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1])\n",
        "\n",
        "print(f\"삭제할 훈련 데이터의 개수 : {len(drop_train)}\")\n",
        "print(f\"삭제할 테스트 데이터의 개수 : {len(drop_test)}\")\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print(f\"훈련 데이터의 개수 : {len(encoder_input_train)}\")\n",
        "print(f\"훈련 레이블의 개수 : {len(decoder_input_train)}\")\n",
        "print(f\"테스트 데이터의 개수 : {len(encoder_input_test)}\")\n",
        "print(f\"테스트 레이블의 개수 : {len(decoder_input_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB9J36qw4R3a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U6P_9Q34R3a"
      },
      "outputs": [],
      "source": [
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7yPqUT34R3a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9puDTo_MRT"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qbNBHBm0LLy"
      },
      "outputs": [],
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "# encoder_lstm2 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm2 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True, dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "# encoder_lstm3 = LSTM(HIDDEN_SIZE, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm3 = LSTM(HIDDEN_SIZE, return_state=True, return_sequences=True, dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giZQZL484R3b"
      },
      "outputs": [],
      "source": [
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, EMBEDDING_DIM)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SSiPXtA4R3b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp4OWJQA4R3b"
      },
      "outputs": [],
      "source": [
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Nfz4wT4R3b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy1iw1_slsf3"
      },
      "outputs": [],
      "source": [
        "fit_kwargs['validation_data'] = ([encoder_input_test, decoder_input_test], decoder_target_test)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "    , loss=\"sparse_categorical_crossentropy\", metrics=['acc']\n",
        ")\n",
        "history = model.fit(\n",
        "            x=[encoder_input_train, decoder_input_train]\n",
        "            , y=decoder_target_train\n",
        "            , **fit_kwargs).history\n",
        "\n",
        "history_dict = model.fit(\n",
        "                         x=[encoder_input_train, decoder_input_train]\n",
        "                         , y=decoder_target_train\n",
        "                         , **fit_kwargs).history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epoch = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epoch, loss, 'bo', label='Training loss')\n",
        "plt.plot(epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNQ9W93B0LUx"
      },
      "source": [
        "학습결과 우하향하는 그래프의 모습을 보이며 train loss, validation loss 의 차이가 크지않다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv2-aMcEvAs7"
      },
      "source": [
        "### 검증\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Soi1Am0_wy"
      },
      "outputs": [],
      "source": [
        "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QYdUOpC4R3c"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEZRY1YZvA39"
      },
      "outputs": [],
      "source": [
        "# 인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(HIDDEN_SIZE,))\n",
        "decoder_state_input_c = Input(shape=(HIDDEN_SIZE,))\n",
        "\n",
        "dec_emb_infer_enc = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "(\n",
        "    decoder_outputs_infer_enc\n",
        "    , state_h_infer_enc\n",
        "    , state_c_infer_enc\n",
        ") = decoder_lstm(dec_emb_infer_enc, initial_state=[decoder_state_input_h, decoder_state_input_c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_PrcpfDvBDR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntsPO6nK4R3c"
      },
      "outputs": [],
      "source": [
        "# 어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, HIDDEN_SIZE))\n",
        "attn_out_inf = attn_layer([decoder_outputs_infer_enc, decoder_hidden_state_input])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs_infer_enc, attn_out_inf])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_outputs_infer_dec = decoder_softmax_layer(decoder_inf_concat)\n",
        "\n",
        "# 최종 디코더 모델\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs_infer_dec] + [state_h2, state_c2])\n",
        "\n",
        "print('=3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KZ2LSN4R3c"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPvlKpzY1B5I"
      },
      "outputs": [],
      "source": [
        "for i in range(50, 100):\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXgwX_Ff1CEc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IifGfd3X4R3d"
      },
      "outputs": [],
      "source": [
        "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
        "print('Summary:')\n",
        "print(summarize(text, ratio=0.005))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsx8OVYGnM-s"
      },
      "source": [
        "### 회고\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngdabGo3j4l"
      },
      "source": [
        "- 학습된 데이터가 전체적으로 높은 정확도를 보여 미리 학습된 데이터의 중요성을 알게되었다.\n",
        "- 항상 학습된 데이터가 높은 정확도를 나타내는 것이 아니라 하이퍼파라미터의 튜닝에 따라 결과가 달라질 수 있다는 것을 알게 되었다.\n",
        "\n",
        "※ 이번 레포트는 양희성님의 모델구조의 조언으로 작성되었음을 알려드립니다.<br>\n",
        "   희성님에게 감사하다는 글을 남기며 이만 글을 마치겠습니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}