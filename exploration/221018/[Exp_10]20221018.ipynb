{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "302ZdfCKLlhI",
        "outputId": "4493f018-dd51-4ddb-cccf-196cfbc2016f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google colab전용\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujMb2MtyLrVQ"
      },
      "source": [
        "# exploration 10번째 과제\n",
        "@ 황한용(3기/쏘카)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdrfR8Y3L0ry"
      },
      "source": [
        "## 라이브러리 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LWLP8EFSLqqp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string # 구두점 정규화 표현식\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tensorflow.keras.preprocessing.sequence.pad_sequences`는 모듈 위치가 변경되었으므로\n",
        "`tf.keras.utils.pad_sequences`로 변경<br>"
      ],
      "metadata": {
        "id": "dwTie8y2eOO0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qC6hZWKL7x3"
      },
      "source": [
        "## 상수선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XcIjEEgnMD75"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/data/translator_seq2seq\" # 데이터 기본경로\n",
        "DATA_PATH  = BASE_PATH + \"/data/fra.txt\" # 사전 기본\n",
        "\n",
        "SOS_TOKEN = '<sos>' # 문장 시작토큰\n",
        "EOS_TOKEN = '<eos>' # 문장 끝 토큰\n",
        "\n",
        "MAX_SAMPLE_LEN = 10000 # 최대 단어갯수\n",
        "SPLIT_LEN = 5000 # validate 갯수\n",
        "PUNCTUATION_REGEX = r'[...|\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]' # 정규화\n",
        "FRENCH_WHITESPACE = r'[\\xa0\\u202f\\u2009]' # whitespace 정규화(1/4 whitespace 등의 대응)\n",
        "FRENCH_APOSTROPHE = r\"’\" # 프랑스어 '\n",
        "FRENCH_DOUBLE_COMMA = r\"'<<|>>'\" # 프랑스어 \"\n",
        "FRENCE_MINUS_REGEX = r\"\\—\" # 프랑스어 -\n",
        "\n",
        "pad_seq_kwargs = {\n",
        "    \"value\":None # 추후 추가예정\n",
        "    , \"padding\":\"post\"\n",
        "    , \"maxlen\":None # 추후 추가예정\n",
        "}\n",
        "TRAIN_TEST_SPLIT_KWARGS = {\n",
        "    \"test_size\":0.08, \"random_state\":2022\n",
        "}\n",
        "fit_kwargs = {\n",
        "    \"epochs\":15 # epoch 횟수\n",
        "    , \"batch_size\":512\n",
        "    ,\"validation_data\": None # 추후 추가예정\n",
        "    , \"shuffle\" : True # epoch당 셔플을 할지의 여부\n",
        "    , \"verbose\":1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어의 경우는 `string.punctuation`의 구두점을 활용하여 만들었다.<br>\n",
        "프랑스어의 경우는 문법에 따라 1/8, 1/4, 1/2 `whitespace`를 표준`whitespace`로 변경하였으며<br>\n",
        "`'`, `\"`, `-` 또한 표준으로 변경하였다.<br>"
      ],
      "metadata": {
        "id": "NtHICg5lZmae"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DV1kd8MPes"
      },
      "source": [
        "## 메인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7XCWajZ0XIj"
      },
      "source": [
        "### 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwkvcfr7MPsm",
        "outputId": "747ba82b-9d9f-4985-8d0f-047f37615a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 197463\n"
          ]
        }
      ],
      "source": [
        "lines = pd.read_csv(DATA_PATH, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5) #샘플 5개 출력\n",
        "lines.pop('cc')\n",
        "lines = lines.head(MAX_SAMPLE_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXm0KjWe845_"
      },
      "source": [
        "데이터에 대한 설명은 아래와 같다.</br>\n",
        "- eng: 영어문장\n",
        "- fra: 영어 문장에 해당되는 프랑스 문장\n",
        "- cc: 저작권 정보\n",
        "\n",
        "저작권 정보는 데이터 분석에 사용되지 않으므로 로드하지 않았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "971TB3kw845_",
        "outputId": "f4dc9e12-55cc-4bc3-fb1a-162533e58e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어장의 크기 : 1995\n",
            "프랑스어 단어장의 크기 : 3947\n",
            "영어 시퀀스의 최대 길이 8\n",
            "프랑스어 시퀀스의 최대 길이 17\n"
          ]
        }
      ],
      "source": [
        "# 구두점(Punctuation)을 단어와 분리\n",
        "# 프랑스 문법에만 존재하는 whitespace -> 표준 whitespace로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_WHITESPACE, r' ', regex=True)\n",
        "#프랑스 문법에만 존재하는 ’를 '로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_APOSTROPHE, r\"'\", regex=True)\n",
        "# 프랑스 문법에만 존재하는 <<, >>를 \"로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_DOUBLE_COMMA, r'\"', regex=True)\n",
        "# 프랑스 문법에만 존재하는 —를 -로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCE_MINUS_REGEX, r\"-\", regex=True)\n",
        "\n",
        "# 구분점에 whitespace를 지음\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(PUNCTUATION_REGEX, r' \\g<0> ', regex=True).replace(' +', ' ', regex=True).str.strip()\n",
        "lines[\"eng\"] = lines[\"eng\"].str.replace(PUNCTUATION_REGEX, r' \\g<0> ', regex=True).replace(' +', ' ', regex=True).str.strip()\n",
        "\n",
        "lines[\"fra\"] = f'{SOS_TOKEN} '+ lines[\"fra\"] + f' {EOS_TOKEN}' # 양옆에 문장의 시작과 끝의 테그를 붙인다.\n",
        "\n",
        "eng_tokenizer = Tokenizer(filters=\"\")  # 문자 단위로 Tokenizer를 생성 \n",
        "eng_tokenizer.fit_on_texts(lines[\"eng\"])\n",
        "encoder_input = eng_tokenizer.texts_to_sequences(lines[\"eng\"])\n",
        "\n",
        "fra_tokenizer = Tokenizer(filters=\"\")\n",
        "fra_tokenizer.fit_on_texts(lines[\"fra\"])\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines[\"fra\"])\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
        "\n",
        "max_eng_seq_len = max(map(len, encoder_input))\n",
        "max_fra_seq_len = max(map(len, target_text))\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어문장와 프랑스문장를 각각 tokenize한 뒤<br>\n",
        "단어 사전의크기, 한 문장의 최대 단어 갯수를 확인<br>\n",
        "이 데이터는 후에 padding에 사용할 예정이다.<br>\n",
        "이번에는 구두점도 임배딩에 필요하므로 필터옵션을 통해 없어지지 않도록 설정하였다.<br>"
      ],
      "metadata": {
        "id": "ajtkCZfqI5ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eos_index = fra_tokenizer.word_index[EOS_TOKEN]\n",
        "sos_index = fra_tokenizer.word_index[SOS_TOKEN]\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[ idx_char for idx_char in line if idx_char != eos_index ] for line in target_text] \n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[ idx_char for idx_char in line if idx_char != sos_index ] for line in target_text]"
      ],
      "metadata": {
        "id": "KZJ8UtVRH2po"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장의 끝 토큰이 제거된 input과<br>\n",
        "문장의 시작 토큰이 제거된 output을 생성"
      ],
      "metadata": {
        "id": "u9EVbvHbH25s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
        "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX-uCKCAK1FQ",
        "outputId": "a731f860-fe9f-4f2a-8af3-e631a87f7fb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기(shape) : (10000, 8)\n",
            "프랑스어 입력데이터의 크기(shape) : (10000, 17)\n",
            "프랑스어 출력데이터의 크기(shape) : (10000, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 언어의 최대 단어갯수에 맞춰 padding을 생성하였다.<br>\n",
        "(`문장의 갯수`,`각 언어의 문장당 단어 최대갯수`)모양의 데이터가 생성되었다.\n"
      ],
      "metadata": {
        "id": "D9kNM2TiK1RF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HbFIKeNV_L8U"
      },
      "outputs": [],
      "source": [
        "(\n",
        " encoder_input_train\n",
        " , encoder_input_test\n",
        " , decoder_input_train\n",
        " , decoder_input_test\n",
        " , decoder_target_train\n",
        " , decoder_target_test\n",
        ") = train_test_split(encoder_input, decoder_input, decoder_target, **TRAIN_TEST_SPLIT_KWARGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQlTE3xms-k0"
      },
      "source": [
        "과적합 방지를 위해 학습과 점증을 10:1비율로 나누었다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9puDTo_MRT"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2qbNBHBm0LLy",
        "outputId": "558509cb-29e5-4c45-cf58-3d33b273e803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 256)    510720      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 17)     67099       ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " masking_2 (Masking)            (None, None, 256)    0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " masking_3 (Masking)            (None, None, 17)     0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 256),        525312      ['masking_2[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 256),  280576      ['masking_3[0][0]',              \n",
            "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 3947)   1014379     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,398,086\n",
            "Trainable params: 2,398,086\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embadding = Embedding(eng_vocab_size, max_eng_seq_len)\n",
        "encoder_masking = Masking(mask_value=0.0)(encoder_embadding(encoder_inputs))\n",
        "encoder_lstm = LSTM(units = max_fra_seq_len, return_state = True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_masking)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "decoder_embadding = Embedding(fra_vocab_size, max_fra_seq_len)\n",
        "decoder_masking = Masking(mask_value=0.0)(decoder_embadding(decoder_inputs))\n",
        "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_masking, initial_state = encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encorder는 영어를 프랑스어로 번역하기 위한 레이어이므로<br>영어 최대길이를 input으로 프랑스어 최대길이를 output으로 크기를 설정하였고<br>decorder는 프랑스어가 번역된 것을 검증하기 위한 레이어이므로 입력, 출력 모두 프랑스어에 맞게 설정하였다."
      ],
      "metadata": {
        "id": "yDMdVE5Grafh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=512, epochs=50).history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epoch = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epoch, loss, 'bo', label='Training loss')\n",
        "plt.plot(epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hy1iw1_slsf3",
        "outputId": "5feb0a41-81cc-4a83-dbd9-ba0a2a3bfe43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 12s 214ms/step - loss: 6.0826 - val_loss: 2.2969\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 2.0370 - val_loss: 1.9215\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 1.8470 - val_loss: 1.8166\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 1.7597 - val_loss: 1.7617\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 1.7111 - val_loss: 1.7269\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 1.6753 - val_loss: 1.6985\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 1.6473 - val_loss: 1.6769\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.6223 - val_loss: 1.6574\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.5976 - val_loss: 1.6350\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.5716 - val_loss: 1.6141\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.5411 - val_loss: 1.5797\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.5045 - val_loss: 1.5441\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.4682 - val_loss: 1.5077\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.4312 - val_loss: 1.4723\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.3975 - val_loss: 1.4408\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.3666 - val_loss: 1.4128\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.3396 - val_loss: 1.3868\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.3134 - val_loss: 1.3636\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.2893 - val_loss: 1.3410\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.2666 - val_loss: 1.3207\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.2446 - val_loss: 1.2998\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.2229 - val_loss: 1.2823\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.2021 - val_loss: 1.2639\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.1810 - val_loss: 1.2442\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.1595 - val_loss: 1.2248\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.1382 - val_loss: 1.2040\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.1145 - val_loss: 1.1828\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.0915 - val_loss: 1.1634\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.0694 - val_loss: 1.1428\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.0483 - val_loss: 1.1265\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.0284 - val_loss: 1.1109\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 1.0090 - val_loss: 1.0947\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.9914 - val_loss: 1.0820\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.9748 - val_loss: 1.0700\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.9583 - val_loss: 1.0573\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.9428 - val_loss: 1.0485\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.9280 - val_loss: 1.0349\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.9129 - val_loss: 1.0231\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.8986 - val_loss: 1.0137\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.8847 - val_loss: 1.0055\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.8716 - val_loss: 0.9959\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.8593 - val_loss: 0.9875\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.8463 - val_loss: 0.9795\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.8341 - val_loss: 0.9720\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.8225 - val_loss: 0.9644\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.8106 - val_loss: 0.9560\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.7988 - val_loss: 0.9481\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.7873 - val_loss: 0.9422\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.7760 - val_loss: 0.9357\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.7650 - val_loss: 0.9278\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5wU5Z3v8c+PYbjOAHIVucyAEYhyZwAVNV6yG1HWu4mGVYkXhPhSxGwM0SSQZMmes/EkhhM1IRrUiEHXbDjeMEYFMZpVAVkUxZNohohXQIFBLnL57R9PNfQM3cMM0zU9U/19v1716u7q6qqnenq+9dRTVU+ZuyMiIsnTIt8FEBGReCjgRUQSSgEvIpJQCngRkYRSwIuIJJQCXkQkoRTwUidmtsjMLsv1tPlkZpVm9sUY5utm9rno+S/M7Lt1mfYQljPRzJ481HLWMt+TzWxdrucrja9lvgsg8TGzrWkv2wE7gT3R66vdfX5d5+Xu4+OYNuncfUou5mNm5cDfgGJ33x3Nez5Q57+hFB4FfIK5e0nquZlVAle6+1M1pzOzlqnQEJHkUBNNAUrtgpvZt8zsA2CemR1mZo+a2Xoz+yR63jvtM0vM7Mro+SQz+5OZ3RJN+zczG3+I0/Yzs6VmVmVmT5nZbWZ2X5Zy16WMPzSz56P5PWlmXdPev8TM1prZRjO7uZbvZ6yZfWBmRWnjzjWzVdHzMWb2ZzPbZGbvm9nPzaxVlnndbWb/mvb6m9Fn3jOzy2tMe6aZvWJmW8zsHTOblfb20uhxk5ltNbPjUt9t2uePN7OXzWxz9Hh8Xb+b2pjZ56PPbzKz1WZ2Vtp7Z5jZ69E83zWzf4nGd43+PpvM7GMze87MlDeNTF944Toc6AyUAZMJv4V50eu+wHbg57V8fizwJtAV+HfgLjOzQ5j2fuAloAswC7iklmXWpYxfBb4GdAdaAanAORq4I5r/EdHyepOBu78IfAqcWmO+90fP9wDTo/U5DjgN+Hot5SYqw+lRef4BOAqo2f7/KXAp0Ak4E5hqZudE750UPXZy9xJ3/3ONeXcGHgPmROv2E+AxM+tSYx0O+G4OUuZi4BHgyehz1wLzzWxgNMldhOa+UmAw8Ew0/hvAOqAb0AO4CVC/KI1MAV+49gIz3X2nu293943u/jt33+buVcBs4Au1fH6tu//K3fcA9wA9Cf/IdZ7WzPoCo4Hvuftn7v4n4OFsC6xjGee5+/939+3Ag8DwaPwFwKPuvtTddwLfjb6DbH4LXAxgZqXAGdE43H25u/+Xu+9290rglxnKkcmXo/K95u6fEjZo6eu3xN1fdfe97r4qWl5d5gthg/AXd/9NVK7fAmuAf0qbJtt3U5tjgRLgf0V/o2eAR4m+G2AXcLSZdXD3T9x9Rdr4nkCZu+9y9+dcHV81OgV84Vrv7jtSL8ysnZn9MmrC2EJoEuiU3kxRwwepJ+6+LXpaUs9pjwA+ThsH8E62AtexjB+kPd+WVqYj0ucdBezGbMsi1NbPM7PWwHnACndfG5VjQNT88EFUjh8RavMHU60MwNoa6zfWzBZHTVCbgSl1nG9q3mtrjFsL9Ep7ne27OWiZ3T19Y5g+3/MJG7+1ZvasmR0Xjf8x8FfgSTN728xm1G01JJcU8IWrZm3qG8BAYKy7d2B/k0C2ZpdceB/obGbt0sb1qWX6hpTx/fR5R8vskm1id3+dEGTjqd48A6GpZw1wVFSOmw6lDIRmpnT3E/Zg+rh7R+AXafM9WO33PULTVbq+wLt1KNfB5tunRvv5vvm6+8vufjah+WYhYc8Ad69y92+4e3/gLOAGMzutgWWRelLAS0opoU17U9SeOzPuBUY14mXALDNrFdX+/qmWjzSkjA8BE8zshOiA6A84+O//fmAaYUPyHzXKsQXYamaDgKl1LMODwCQzOzrawNQsfylhj2aHmY0hbFhS1hOalPpnmffjwAAz+6qZtTSzrwBHE5pTGuJFQm3/RjMrNrOTCX+jBdHfbKKZdXT3XYTvZC+AmU0ws89Fx1o2E45b1NYkJjFQwEvKrUBbYAPwX8ATjbTciYQDlRuBfwUeIJyvn8khl9HdVwPXEEL7feATwkHA2qTawJ9x9w1p4/+FEL5VwK+iMtelDIuidXiG0HzxTI1Jvg78wMyqgO8R1Yajz24jHHN4Pjoz5dga894ITCDs5WwEbgQm1Ch3vbn7Z4RAH0/43m8HLnX3NdEklwCVUVPVFMLfE8JB5KeArcCfgdvdfXFDyiL1ZzruIU2JmT0ArHH32PcgRJJONXjJKzMbbWZHmlmL6DTCswltuSLSQLqSVfLtcOA/CQc81wFT3f2V/BZJJBnURCMiklBqohERSagm1UTTtWtXLy8vz3cxRESajeXLl29w926Z3mtSAV9eXs6yZcvyXQwRkWbDzGpewbyPmmhERBJKAS8iklAKeBGRhGpSbfAi0rh27drFunXr2LFjx8Enlrxq06YNvXv3pri4uM6fUcCLFLB169ZRWlpKeXk52e/XIvnm7mzcuJF169bRr1+/On+u2TfRzJ8P5eXQokV4nK9bEIvU2Y4dO+jSpYvCvYkzM7p06VLvPa1mXYOfPx8mT4Zt0e0i1q4NrwEmTsz+ORHZT+HePBzK36lZ1+Bvvnl/uKds2xbGi4gUulgD3sw6mdlDZrbGzN5Iu51XTvz97/UbLyJNy8aNGxk+fDjDhw/n8MMPp1evXvtef/bZZ7V+dtmyZVx33XUHXcbxxx+fk7IuWbKECRMm5GRejSXuGvzPgCfcfRAwDHgjlzPvW/OGZwcZLyINk+tjXl26dGHlypWsXLmSKVOmMH369H2vW7Vqxe7du7N+tqKigjlz5hx0GS+88ELDCtmMxRbwZtaRcKuzuyDcGcbdN+VyGbNnQ7t21ce1axfGi0hupY55rV0L7vuPeeX6xIZJkyYxZcoUxo4dy4033shLL73Ecccdx4gRIzj++ON58803geo16lmzZnH55Zdz8skn079//2rBX1JSsm/6k08+mQsuuIBBgwYxceJEUr3pPv744wwaNIhRo0Zx3XXXHbSm/vHHH3POOecwdOhQjj32WFatWgXAs88+u28PZMSIEVRVVfH+++9z0kknMXz4cAYPHsxzzz2X2y+sFnEeZO1HuI/kPDMbBiwHpkV3s9/HzCYDkwH61rPqnTqQevPNoVmmb98Q7jrAKpJ7tR3zyvX/3Lp163jhhRcoKipiy5YtPPfcc7Rs2ZKnnnqKm266id/97ncHfGbNmjUsXryYqqoqBg4cyNSpUw84Z/yVV15h9erVHHHEEYwbN47nn3+eiooKrr76apYuXUq/fv24+OKLD1q+mTNnMmLECBYuXMgzzzzDpZdeysqVK7nlllu47bbbGDduHFu3bqVNmzbMnTuXL33pS9x8883s2bOHbTW/xBjF2UTTEhgJ3OHuI4BPgRk1J3L3ue5e4e4V3bpl7BCtVhMnQmUl7N0bHhXuIvFozGNeF154IUVFRQBs3ryZCy+8kMGDBzN9+nRWr16d8TNnnnkmrVu3pmvXrnTv3p0PP/zwgGnGjBlD7969adGiBcOHD6eyspI1a9bQv3//feeX1yXg//SnP3HJJZcAcOqpp7Jx40a2bNnCuHHjuOGGG5gzZw6bNm2iZcuWjB49mnnz5jFr1ixeffVVSktLD/Vrqbc4A34dsM7dX4xeP0QIfBFphhrzmFf79u33Pf/ud7/LKaecwmuvvcYjjzyS9Vzw1q1b73teVFSUsf2+LtM0xIwZM7jzzjvZvn0748aNY82aNZx00kksXbqUXr16MWnSJO69996cLrM2sQW8u38AvGNmA6NRpwGvx7U8EYlXvo55bd68mV69egFw991353z+AwcO5O2336ayshKABx544KCfOfHEE5kfHXxYsmQJXbt2pUOHDrz11lsMGTKEb33rW4wePZo1a9awdu1aevTowVVXXcWVV17JihUrcr4O2cR9Fs21wHwzWwUMB34U8/JEJCYTJ8LcuVBWBmbhce7c+JtFb7zxRr797W8zYsSInNe4Adq2bcvtt9/O6aefzqhRoygtLaVjx461fmbWrFksX76coUOHMmPGDO655x4Abr31VgYPHszQoUMpLi5m/PjxLFmyhGHDhjFixAgeeOABpk2blvN1yKZJ3ZO1oqLCdcMPkcbzxhtv8PnPfz7fxci7rVu3UlJSgrtzzTXXcNRRRzF9+vR8F+sAmf5eZrbc3SsyTd+sr2QVEcmFX/3qVwwfPpxjjjmGzZs3c/XVV+e7SDnRrPuiERHJhenTpzfJGntDqQYvIpJQCngRkYRSwIuIJJQCXkQkoRTwIpI3p5xyCn/4wx+qjbv11luZOnVq1s+cfPLJpE6nPuOMM9i06cA+DGfNmsUtt9xS67IXLlzI66/vv/bye9/7Hk899VR9ip9RU+pWWAEvInlz8cUXs2DBgmrjFixYUKf+YCD0AtmpU6dDWnbNgP/BD37AF7/4xUOaV1OlgBeRvLngggt47LHH9t3co7Kykvfee48TTzyRqVOnUlFRwTHHHMPMmTMzfr68vJwNGzYAMHv2bAYMGMAJJ5ywr0thCOe4jx49mmHDhnH++eezbds2XnjhBR5++GG++c1vMnz4cN566y0mTZrEQw89BMDTTz/NiBEjGDJkCJdffjk7d+7ct7yZM2cycuRIhgwZwpo1a2pdv3x3K6zz4EUEgOuvh5UrczvP4cPh1luzv9+5c2fGjBnDokWLOPvss1mwYAFf/vKXMTNmz55N586d2bNnD6eddhqrVq1i6NChGeezfPlyFixYwMqVK9m9ezcjR45k1KhRAJx33nlcddVVAHznO9/hrrvu4tprr+Wss85iwoQJXHDBBdXmtWPHDiZNmsTTTz/NgAEDuPTSS7njjju4/vrrAejatSsrVqzg9ttv55ZbbuHOO+/Mun757lZYNXgRyav0Zpr05pkHH3yQkSNHMmLECFavXl2tOaWm5557jnPPPZd27drRoUMHzjrrrH3vvfbaa5x44okMGTKE+fPnZ+1uOOXNN9+kX79+DBgwAIDLLruMpUuX7nv/vPPOA2DUqFH7OijLJt/dCqsGLyJA7TXtOJ199tlMnz6dFStWsG3bNkaNGsXf/vY3brnlFl5++WUOO+wwJk2alLWb4IOZNGkSCxcuZNiwYdx9990sWbKkQeVNdTnckO6GZ8yYwZlnnsnjjz/OuHHj+MMf/rCvW+HHHnuMSZMmccMNN3DppZc2qKyqwYtIXpWUlHDKKadw+eWX76u9b9myhfbt29OxY0c+/PBDFi1aVOs8TjrpJBYuXMj27dupqqrikUce2fdeVVUVPXv2ZNeuXfu6+AUoLS2lqqrqgHkNHDiQyspK/vrXvwLwm9/8hi984QuHtG757lZYNXgRybuLL76Yc889d19TTap73UGDBtGnTx/GjRtX6+dHjhzJV77yFYYNG0b37t0ZPXr0vvd++MMfMnbsWLp168bYsWP3hfpFF13EVVddxZw5c/YdXAVo06YN8+bN48ILL2T37t2MHj2aKVOmHNJ6pe4VO3ToUNq1a1etW+HFixfTokULjjnmGMaPH8+CBQv48Y9/THFxMSUlJTm5MYi6CxYpYOouuHlRd8EiIgIo4EVEEksBL1LgmlIzrWR3KH8nBbxIAWvTpg0bN25UyDdx7s7GjRtp06ZNvT6ns2hECljv3r1Zt24d69evz3dR5CDatGlD79696/UZBbxIASsuLqZfv375LobERE00IiIJpYAXEUkoBbyISEIp4EVEEkoBLyKSUAp4EZGEUsCLiCRUrOfBm1klUAXsAXZn6/FMRERyrzEudDrF3Tc0wnJERCSNmmhERBIq7oB34EkzW25mkzNNYGaTzWyZmS1TfxgiIrkTd8Cf4O4jgfHANWZ2Us0J3H2uu1e4e0W3bt1iLo6ISOGINeDd/d3o8SPg98CYOJcnIiL7xRbwZtbezEpTz4F/BF6La3kiIlJdnGfR9AB+b2ap5dzv7k/EuDwREUkTW8C7+9vAsLjmLyIitdNpkiIiCaWAFxFJKAW8iEhCKeBFRBJKAS8iklAKeBGRhFLAi4gklAJeRCShFPAiIgmlgBcRSSgFvIhIQingRUQSSgEvIpJQCngRkYRSwIuIJJQCXkQkoRTwIiIJpYAXEUkoBbyISEIp4EVEEkoBLyKSUAp4EZGEUsCLiCSUAl5EJKEU8CIiCaWAFxFJKAW8iEhCKeBFRBJKAS8iklCxB7yZFZnZK2b2aNzLEhGR/RqjBj8NeKMRliMiImliDXgz6w2cCdwZ53JERORAcdfgbwVuBPZmm8DMJpvZMjNbtn79+piLIyJSOGILeDObAHzk7strm87d57p7hbtXdOvWLa7iiIgUnDhr8OOAs8ysElgAnGpm98W4PBERSRNbwLv7t929t7uXAxcBz7j7P8e1PBERqU7nwYuIJFTLxliIuy8BljTGskREJFANXkQkoRTwIiIJpYAXEUkoBbyISEIp4EVEEkoBLyKSUAp4EZGEqlPAm1l7M2sRPR9gZmeZWXG8RRMRkYaoaw1+KdDGzHoBTwKXAHfHVSgREWm4uga8ufs24Dzgdne/EDgmvmKJiEhD1Tngzew4YCLwWDSuKJ4iiYhILtQ14K8Hvg383t1Xm1l/YHF8xRIRkYaqU2dj7v4s8CxAdLB1g7tfF2fBRESkYep6Fs39ZtbBzNoDrwGvm9k34y2aiIg0RF2baI529y3AOcAioB/hTBoREWmi6hrwxdF57+cAD7v7LsDjK5aIiDRUXQP+l0Al0B5YamZlwJa4CiUiIg1X14Osc4A5aaPWmtkp8RRJRERyoa4HWTua2U/MbFk0/B9CbV5ERJqoujbR/BqoAr4cDVuAeXEVSkREGq6uN90+0t3PT3v9fTNbGUeBREQkN+pag99uZiekXpjZOGB7PEUSEZFcqGsNfgpwr5l1jF5/AlwWT5FERCQX6noWzX8Dw8ysQ/R6i5ldD6yKs3AiInLo6nVHJ3ffEl3RCnBDDOUREZEcacgt+yxnpRARkZxrSMCrqwIRkSas1jZ4M6sic5Ab0DaWEomISE7UGvDuXnqoMzazNoR7ubaOlvOQu8881PmJiEj91PU0yUOxEzjV3bdGPVH+ycwWuft/xbhMERGJxBbw7u7A1uhlcTSo3V5EpJE05CDrQZlZUdSlwUfAH939xQzTTE51YrZ+/fo4iyMiUlBiDXh33+Puw4HewBgzG5xhmrnuXuHuFd26dYuzOCIiBSXWgE9x903AYuD0xlieiIjEGPBm1s3MOkXP2wL/AKyJa3kiIlJdnGfR9ATuMbMiwobkQXd/NMbliYhImjjPolkFjIhr/iIiUrtGaYMXEZHGp4AXEUkoBbyISEIp4EVEEkoBLyKSUAp4EZGEUsCLiCSUAl5EJKEU8CIiCaWAFxFJKAW8iEhCKeBFRBJKAS8iklAKeBGRhFLAi4gklAJeRCShFPAiIgmlgBcRSajEBLx7vksgItK0NPuA37IFvvQlmDs33yUREWlamn3Al5bCxx/DT38Ke/fmuzQiIk1Hsw94M7jhBnjzTVi0KN+lERFpOpp9wANccAH07g0/+Um+SyIi0nQkIuCLi+G66+CZZ2DlynyXRkSkaUhEwANcdRW0bx/a4kVEJEEB36kTXHEF/Pa38N57+S6NiEj+JSbgAaZNg9274bbb8l0SEZH8S1TA9+8P554Lv/gF3HUXlJdDixbhcf78fJdORKRxxRbwZtbHzBab2etmttrMpsW1rHQ33BDOi586FdauDVe4rl0Lkycr5EWksMRZg98NfMPdjwaOBa4xs6NjXB4Axx8PrVrBrl3Vx2/bBjffHPfSRUSajtgC3t3fd/cV0fMq4A2gV1zLSzGDzz7L/N7f/x730kVEmo5GaYM3s3JgBPBihvcmm9kyM1u2fv36nCyvb9/6jRcRSaLYA97MSoDfAde7+5aa77v7XHevcPeKbt265WSZP/pRuPgpXbt2MHt2TmYvItIsxBrwZlZMCPf57v6fcS4r3cSJ8POfh+YaCN0YzJ0bxouIFIo4z6Ix4C7gDXdv9F5iJk+GX/4yHHDduhU+/TT0Njl/vk6fFJHCYB7TnTLM7ATgOeBVINWR703u/ni2z1RUVPiyZctyWo4334QpU2DJEhgwIBxo3bFj//vt2ql2LyLNl5ktd/eKjO/FFfCHIo6Ah3Au/N13w5VXZu4zvqwMKitzvlgRkdjVFvCJupI1GzP42tey3xBk7Vo13YhI8hREwKeUlWUe36IFTJqkK19FJFkKKuBnzw5t7ulatYKiotBJWbpt20K3B5s3q3YvIs1TQQX8xInhgGpZWWi2KSuDX//6wHBP+eij0A3xJZdUr91feSXcd5+CX0SatoI4yHow5eUhuGvq3j10e7Bp04HvmYUhvV2/dWu49VYoKYHvfCecsdO3b9hz0Fk6IhKHgj/IejCZmm7atQv3eN28OfNn3A88aLtzZ+jFsmaN/2tfg2uvhVmzwkVXZqrxi0j8FPBkbrpJnRufi/5rdu0KV9Z+//vw7rth3Nq1cOml8MUvwle/GvYWzMLyFPwikgtqojmI+fPDGTXbtu0f164dtG0LGzc2fP5moaZfU1kZjBgRLsp68UX45BPo0wf+7d/U3CMi+6mJpgGy1e5/9rPMzTpdutRv/tm2rx99BMuWwRNPhHAHeOed0Pxzwgmh9t+zp5p7RCQ71eAbYP78cBOR9IOpkJsaf6q5JtPB30y1/pYt4fLL4cgjwz1p33lHB3hFCkHBd1XQ2HIR/GVl4fMN/fO0bg0//Wk4+CsiyaMmmkY2cWLo22bv3vA4cWL9m3pmz87NAd6dO+HrX4cePaB9+7Dsnj1D3zwikmyqwTcBmWr8Eyfm9gBvURHs2VN9XP/+MH58GP/ww/Dee2HDo2YdkeZDTTTNWC6aezKFO4TmG7Pq3SdDaM+/7LKwvDvvhHXr1J4v0lQp4BOoPsGf/jqdWTj1sq43I2/ZMvStf/XVoW/9Vq0atg4i0nAK+AKSKfhvvjnz2Ti5OJDbti2cdhqcfz4MGgQDB8Jhhx36/ESkfhTwBS5bW/7cudnDvzatWoU+eg42zejR4Urdz30unL555JHQrdv+e+WKSMPVFvAtG7sw0vhS7eaZDuRC/dvzM4V7p06wfXs4awfCNC+8EIb0OkSqWWjUqBD4GzfCY4+FC7v69oUf/Ujt/CK5ohq85KQ9P5vOncNn0g/ktmgBhx8O69eHfnpqOvJI6NoV3ngDtmwJ/fR84xtwzTXhVE8R2U9NNHJI6tOeX19lZaFmn+kAb3Fx6KM/00+zQ4ewsfjsMygthTPOgAkToFev/YM2AlJIFPCSM7k6Nz/VDl+fn1/btiHYM53yma5FixD0gweH7pl79w7NQn37hqFPH2jTpu7LFWnK1AYvOZOtPR/qF/ypq3TrszewfXvm8TXb//fuDRdtFRXB88+HZp6auncPNf0PPwxlPuyw0JFbqovo7t3DhkKkOVMNXnKmPm35c+dmfy9XXTF36RKCP33+rVrBWWeF+T/77IE3bampTRsYOzacDVRevn/o2TNsQETyTTV4aRSpPncyyXYGT6b3IDfBn2nazz6Dl18OzzOFe2lpaONPHfzdsSNsCJ599sBpe/SAIUNC4PfrFx5TTUBHHBGOJYjkk2rw0iTF3RUz1K/9P9PZQEVFIdTXrz+wGahFixDyqXb/srIwbfpjzU7mRA6FavDS7NRnbwDib///+OMDx+3ZE27Ivnt39fGtWoWzezp2DHsLL7104DQQLvrq1Ss092QaDj887CVoQyCHSgEvzUougr8xmoFeeSUs5z/+o3q4t24NV1wRav2LFsHKlfD66+GA75Ytmc8QKi0NYZ8aMm0IDj887GW01H+0pNHPQRKhqbX///3vYd41LwzbuRMeeKD6wd/PPgvBfOWVcO+91c8WKi6G44+HzZvDnsDOndnv4wvhbKAuXcLQtev+5507h6Hm865d998nQJIntjZ4M/s1MAH4yN0H1+UzaoOXpiBfd+TK1q1zprOB2raFH/4wBP8dd8CGDaFJaMyYMP3GjfCXv4RbNx7suoFWrfZvDLp2DRuJ0tJwUVn6Y6dO4f1u3fYPrVvXff0kHnm50MnMTgK2Avcq4CUJ6nsaaK6u+s0mU/DXdgpq27YwaxZs3Qq/+EVoJurUKdzEvUePsJHYsCFsNLZsCUNVVe0biNLSEPSpvYKaQ8eOYejQIQyp56WlYc9B1xo0XN6uZDWzcuBRBbwkWa7uyJWtBl9fZWXhMdPG5WAbhZrr8dWvwrx5MHNmuPFLjx5w0UVw9NFhA7FhQ3j85JOwTh9/HIZPPjn4NQYQQr60FEpKwmNpafWNQvrz1Pvp06aG9u0L9/hDkw54M5sMTAbo27fvqLVxVnlEGll9av2XXQb33JOf00CzBX+2MmXbIKSOb/zmN3DTTWGj0LNnOL5w7LFhr2Dz5rBnUFUV9ibSn6f2HFJ7EZs3Zz4DKZM2bfaHf0lJCP2SkurPDzau5kYkddezpqxJB3w61eClUNRW689F+z/kpnmoPscFDnaFcm0bhWzfh3u49iB9o1Bz2Lq1+pAa/+mn+4etW6s/1lXLlvsDP33jkdowpP4OqSH1Ov0xfUjfmJSU5GavQwEv0sw1tW4gsjmU5qFD2UvItkGoi717QzlSgZ8K/Zp7FOlD+rTpG5Xt2/evU817G9dFaq+jTx9YsaL+nwdd6CTS7OXrNND6Hheo7f6+mea/bVsI8prL2LYNpk2rvkFYuzaU/fnnq28QUuOh9vBvyEahLlJ7G+mhX3NI31Ckbyxiu7+xu8cyAL8F3gd2AeuAKw72mVGjRrmIxOu++9zLytzNwuN994WhXTv3EFNhaNfOferUzOO7dKk+LjWUlYUh03u5GoqKsi+7vuuRWvea30e276kpApZ5thzO9kY+BgW8SP7UJ+iyBWlt72XbKGQL7PoOqfLVZxldutR/g1Df7ypuCngRybnawizOvYTaavBmudlYNKe9BAW8iDQJudhLqC1I61uDb8p7CXWlgBeRZqm+Nd+k7CXUhwJeRApGEvYS6kMBLyKSRVPcS6iP2gJeXf2ISEGbOBEqK8MFUGaHl9UAAAWxSURBVJWV+8+Nr2383Lnhoi6z8Dh3Ltx+e+bxP/vZgTdtadcunLufaXzqeoVc0C37RERiFufFV3nrqqC+FPAiIvVTW8CriUZEJKEU8CIiCaWAFxFJKAW8iEhCKeBFRBKqSZ1FY2brgYPdh6YrsKERitPUaL0Li9a7sDRkvcvcvVumN5pUwNeFmS3LdkpQkmm9C4vWu7DEtd5qohERSSgFvIhIQjXHgJ+b7wLkida7sGi9C0ss693s2uBFRKRummMNXkRE6kABLyKSUM0m4M3sdDN708z+amYz8l2eOJnZr83sIzN7LW1cZzP7o5n9JXo8LJ9lzDUz62Nmi83sdTNbbWbTovFJX+82ZvaSmf13tN7fj8b3M7MXo9/7A2bWKt9ljYOZFZnZK2b2aPS6UNa70sxeNbOVZrYsGpfz33qzCHgzKwJuA8YDRwMXm9nR+S1VrO4GTq8xbgbwtLsfBTwdvU6S3cA33P1o4FjgmuhvnPT13gmc6u7DgOHA6WZ2LPC/gZ+6++eAT4Ar8ljGOE0D3kh7XSjrDXCKuw9PO/8957/1ZhHwwBjgr+7+trt/BiwAzs5zmWLj7kuBj2uMPhu4J3p+D3BOoxYqZu7+vruviJ5XEf7pe5H89XZ33xq9LI4GB04FHorGJ269AcysN3AmcGf02iiA9a5Fzn/rzSXgewHvpL1eF40rJD3c/f3o+QdAj3wWJk5mVg6MAF6kANY7aqZYCXwE/BF4C9jk7rujSZL6e78VuBHYG73uQmGsN4SN+JNmttzMJkfjcv5bb9nQGUjjc3c3s0Se32pmJcDvgOvdfUuo1AVJXW933wMMN7NOwO+BQXkuUuzMbALwkbsvN7OT812ePDjB3d81s+7AH81sTfqbufqtN5ca/LtAn7TXvaNxheRDM+sJED1+lOfy5JyZFRPCfb67/2c0OvHrneLum4DFwHFAJzNLVcCS+HsfB5xlZpWEJtdTgZ+R/PUGwN3fjR4/ImzUxxDDb725BPzLwFHREfZWwEXAw3kuU2N7GLgsen4Z8P/yWJaci9pf7wLecPefpL2V9PXuFtXcMbO2wD8Qjj8sBi6IJkvcerv7t929t7uXE/6fn3H3iSR8vQHMrL2ZlaaeA/8IvEYMv/VmcyWrmZ1BaLMrAn7t7rPzXKTYmNlvgZMJXYh+CMwEFgIPAn0JXSp/2d1rHohttszsBOA54FX2t8neRGiHT/J6DyUcUCsiVLgedPcfmFl/Qs22M/AK8M/uvjN/JY1P1ETzL+4+oRDWO1rH30cvWwL3u/tsM+tCjn/rzSbgRUSkfppLE42IiNSTAl5EJKEU8CIiCaWAFxFJKAW8iEhCKeAl8cxsT9RrX2rIWYdlZlae3uunSFOirgqkEGx39+H5LoRIY1MNXgpW1Cf3v0f9cr9kZp+Lxpeb2TNmtsrMnjazvtH4Hmb2+6jv9v82s+OjWRWZ2a+i/tyfjK5Ixcyui/q3X2VmC/K0mlLAFPBSCNrWaKL5Stp7m919CPBzwpXSAP8XuMfdhwLzgTnR+DnAs1Hf7SOB1dH4o4Db3P0YYBNwfjR+BjAims+UuFZOJBtdySqJZ2Zb3b0kw/hKws023o46OvvA3buY2Qagp7vvisa/7+5dzWw90Dv90vmoa+M/RjdpwMy+BRS7+7+a2RPAVkI3EwvT+n0XaRSqwUuh8yzP6yO9r5Q97D+2dSbhTmQjgZfTekkUaRQKeCl0X0l7/HP0/AVCD4cAEwmdoEG4jdpU2HeTjo7ZZmpmLYA+7r4Y+BbQEThgL0IkTqpRSCFoG90xKeUJd0+dKnmYma0i1MIvjsZdC8wzs28C64GvReOnAXPN7ApCTX0q8D6ZFQH3RRsBA+ZE/b2LNBq1wUvBitrgK9x9Q77LIhIHNdGIiCSUavAiIgmlGryISEIp4EVEEkoBLyKSUAp4EZGEUsCLiCTU/wDZfmfKY0ydagAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNQ9W93B0LUx"
      },
      "source": [
        "학습결과 우하향하는 그래프의 모습을 보이며 train loss, validation loss 의 차이가 크지않다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증\n"
      ],
      "metadata": {
        "id": "mv2-aMcEvAs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
        "encoder_model.summary()\n",
        "\n",
        "# 이전 time step의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "# 이전 time step의 cell state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_embadding_val = decoder_embadding(decoder_inputs)\n",
        "\n",
        "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
        "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
        "decoder_outputs_val, state_h, state_c = decoder_lstm(decoder_embadding(decoder_inputs), initial_state = decoder_states_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
        "decoder_states_val = [state_h, state_c]\n",
        "\n",
        "decoder_outputs_val = decoder_softmax_layer(decoder_outputs_val)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs_val] + decoder_states_val)\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "id": "BEZRY1YZvA39",
        "outputId": "d6ffe3f4-71fe-49ff-efa6-8ea00dffd0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         510720    \n",
            "                                                                 \n",
            " masking_2 (Masking)         (None, None, 256)         0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               [(None, 256),             525312    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,036,032\n",
            "Trainable params: 1,036,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 17)     67099       ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 256),  280576      ['embedding_3[2][0]',            \n",
            "                                 (None, 256),                     'input_7[0][0]',                \n",
            "                                 (None, 256)]                     'input_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 3947)   1014379     ['lstm_3[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,362,054\n",
            "Trainable params: 1,362,054\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6_PrcpfDvBDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "metadata": {
        "id": "m1Soi1Am0_wy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Q_oqPgi0_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = fra2idx[SOS_TOKEN]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == EOS_TOKEN or\n",
        "           len(decoded_sentence) > max_fra_seq_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros(1, 1)\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "wPvlKpzY1B5I"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EXgwX_Ff1CEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.eng[seq_index])\n",
        "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
      ],
      "metadata": {
        "id": "S5eU9KvT1XZl",
        "outputId": "7fe40abd-6be5-41fe-b90c-7ad9bf82df3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 352ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-15d12ce5dbdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 입력 문장의 인덱스 (자유롭게 선택해 보세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'입력 문장:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6d1d47848f53>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_token_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '1' as a data type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E7-ju2Gp1Xko"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsx8OVYGnM-s"
      },
      "source": [
        "### 회고\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngdabGo3j4l"
      },
      "source": [
        "- 학습된 데이터가 전체적으로 높은 정확도를 보여 미리 학습된 데이터의 중요성을 알게되었다.\n",
        "- 항상 학습된 데이터가 높은 정확도를 나타내는 것이 아니라 하이퍼파라미터의 튜닝에 따라 결과가 달라질 수 있다는 것을 알게 되었다.\n",
        "\n",
        "※ 이번 레포트는 양희성님의 모델구조의 조언으로 작성되었음을 알려드립니다.<br>\n",
        "   희성님에게 감사하다는 글을 남기며 이만 글을 마치겠습니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}