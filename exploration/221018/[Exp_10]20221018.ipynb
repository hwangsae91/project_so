{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwangsae91/project_so/blob/master/exploration/221018/%5BExp_10%5D20221018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "302ZdfCKLlhI",
        "outputId": "717ea18e-17a9-4b2c-ef85-3494c24abf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google colab전용\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujMb2MtyLrVQ"
      },
      "source": [
        "# exploration 10번째 과제\n",
        "@ 황한용(3기/쏘카)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdrfR8Y3L0ry"
      },
      "source": [
        "## 라이브러리 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LWLP8EFSLqqp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import string # 구두점 정규화 표현식\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tensorflow.keras.preprocessing.sequence.pad_sequences`는 모듈 위치가 변경되었으므로\n",
        "`tf.keras.utils.pad_sequences`로 변경<br>"
      ],
      "metadata": {
        "id": "dwTie8y2eOO0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qC6hZWKL7x3"
      },
      "source": [
        "## 상수선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XcIjEEgnMD75"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/data/translator_seq2seq\" # 데이터 기본경로\n",
        "DATA_PATH  = BASE_PATH + \"/data/fra.txt\" # 사전 기본\n",
        "\n",
        "SOS_TOKEN = '<sos>' # 문장 시작토큰\n",
        "EOS_TOKEN = '<eos>' # 문장 끝 토큰\n",
        "\n",
        "MAX_SAMPLE_LEN = 55000 # 최대 단어갯수\n",
        "VALID_LEN = 5000 # 검증할 문장의 갯수\n",
        "PUNCTUATION_REGEX = r'[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]' # 정규화\n",
        "FRENCH_WHITESPACE = r'[\\xa0\\u202f\\u2009]' # whitespace 정규화(1/4 whitespace 등의 대응)\n",
        "FRENCH_APOSTROPHE = r\"’\" # 프랑스어 '\n",
        "FRENCH_DOUBLE_COMMA = r\"'<<|>>'\" # 프랑스어 \"\n",
        "FRENCE_MINUS_REGEX = r\"\\—\" # 프랑스어 -\n",
        "\n",
        "pad_seq_kwargs = {\n",
        "    \"value\":None # 추후 추가예정\n",
        "    , \"padding\":\"post\"\n",
        "    , \"maxlen\":None # 추후 추가예정\n",
        "}\n",
        "TRAIN_TEST_SPLIT_KWARGS = {\n",
        "    \"test_size\":0.08, \"random_state\":2022\n",
        "}\n",
        "\n",
        "HIDDEN_STATE_NUM = 64 # hidden state의 노드수\n",
        "\n",
        "fit_kwargs = {\n",
        "    \"epochs\":50 # epoch 횟수\n",
        "    , \"batch_size\":HIDDEN_STATE_NUM\n",
        "    ,\"validation_data\": None # 추후 추가예정\n",
        "    , \"shuffle\" : True # epoch당 셔플을 할지의 여부\n",
        "    , \"verbose\":1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어의 경우는 `string.punctuation`의 구두점을 활용하여 만들었다.<br>\n",
        "프랑스어의 경우는 문법에 따라 1/8, 1/4, 1/2 `whitespace`를 표준`whitespace`로 변경하였으며<br>\n",
        "`'`, `\"`, `-` 또한 표준으로 변경하였다.<br>\n",
        "알파벳의 악쌍(악센트, 성조)은 단어의 의미를 결정하는 요소이므로 제거하지 않았다."
      ],
      "metadata": {
        "id": "NtHICg5lZmae"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DV1kd8MPes"
      },
      "source": [
        "## 메인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7XCWajZ0XIj"
      },
      "source": [
        "### 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwkvcfr7MPsm",
        "outputId": "87cb81b6-3295-4c72-b6ff-0f4796b41e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 197463\n"
          ]
        }
      ],
      "source": [
        "lines = pd.read_csv(DATA_PATH, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5) #샘플 5개 출력\n",
        "lines.pop('cc')\n",
        "lines = lines.head(MAX_SAMPLE_LEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXm0KjWe845_"
      },
      "source": [
        "데이터에 대한 설명은 아래와 같다.</br>\n",
        "- eng: 영어문장\n",
        "- fra: 영어 문장에 해당되는 프랑스 문장\n",
        "- cc: 저작권 정보\n",
        "\n",
        "저작권 정보는 데이터 분석에 사용되지 않으므로 로드하지 않았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "971TB3kw845_",
        "outputId": "347f72d2-03f3-45bc-90ad-a9d6b5bd2642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어장의 크기 : 6386\n",
            "프랑스어 단어장의 크기 : 11450\n",
            "영어 시퀀스의 최대 길이 11\n",
            "프랑스어 시퀀스의 최대 길이 19\n"
          ]
        }
      ],
      "source": [
        "# 구두점(Punctuation)을 단어와 분리\n",
        "# 프랑스 문법에만 존재하는 whitespace -> 표준 whitespace로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_WHITESPACE, r' ', regex=True)\n",
        "#프랑스 문법에만 존재하는 ’를 '로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_APOSTROPHE, r\"'\", regex=True)\n",
        "# 프랑스 문법에만 존재하는 <<, >>를 \"로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCH_DOUBLE_COMMA, r'\"', regex=True)\n",
        "# 프랑스 문법에만 존재하는 —를 -로 변경\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(FRENCE_MINUS_REGEX, r\"-\", regex=True)\n",
        "\n",
        "# 구분점에 whitespace를 지음\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(PUNCTUATION_REGEX, r' \\g<0> ', regex=True).replace(' +', ' ', regex=True).str.strip()\n",
        "lines[\"eng\"] = lines[\"eng\"].str.replace(PUNCTUATION_REGEX, r' \\g<0> ', regex=True).replace(' +', ' ', regex=True).str.strip()\n",
        "lines[\"fra\"] = lines[\"fra\"].str.replace(' +', ' ', regex=True)\n",
        "lines[\"eng\"] = lines[\"eng\"].str.replace(' +', ' ', regex=True)\n",
        "\n",
        "lines[\"fra_decoder_input\"] = f'{SOS_TOKEN} '+ lines[\"fra\"]\n",
        "lines[\"fra_decoder_target\"] = lines[\"fra\"] + f' {EOS_TOKEN}'\n",
        "lines[\"fra\"] = f'{SOS_TOKEN} '+ lines[\"fra\"] + f' {EOS_TOKEN}' # 양옆에 문장의 시작과 끝의 테그를 붙인다.\n",
        "\n",
        "lines[\"eng\"] = lines[\"eng\"].str.split()\n",
        "\n",
        "lines[\"fra\"] = lines[\"fra\"].str.split()\n",
        "lines[\"fra_decoder_input\"] = lines[\"fra_decoder_input\"].str.split()\n",
        "lines[\"fra_decoder_target\"] = lines[\"fra_decoder_target\"].str.split()\n",
        "\n",
        "eng_tokenizer = Tokenizer(filters=\"\")  # 문자 단위로 Tokenizer를 생성 \n",
        "eng_tokenizer.fit_on_texts(lines[\"eng\"])\n",
        "encoder_input = eng_tokenizer.texts_to_sequences(lines[\"eng\"])\n",
        "\n",
        "fra_tokenizer = Tokenizer(filters=\"\")\n",
        "fra_tokenizer.fit_on_texts(lines[\"fra\"])\n",
        "\n",
        "decoder_input = fra_tokenizer.texts_to_sequences(lines[\"fra_decoder_input\"])\n",
        "decoder_target = fra_tokenizer.texts_to_sequences(lines[\"fra_decoder_target\"])\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
        "\n",
        "max_eng_seq_len = max(map(len, encoder_input))\n",
        "max_fra_seq_len = max(map(len, decoder_input))\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어문장와 프랑스문장를 각각 tokenize한 뒤<br>\n",
        "단어 사전의크기, 한 문장의 최대 단어 갯수를 확인<br>\n",
        "이 데이터는 후에 padding에 사용할 예정이다.<br>\n",
        "문장의 끝 토큰이 제거된 input과<br>\n",
        "문장의 시작 토큰이 제거된 output을 각각 데이터 프레임에서 생산하였으며<br>\n",
        "이번에는 구두점도 임배딩에 필요하므로 필터옵션을 통해 없어지지 않도록 설정하였다.<br>"
      ],
      "metadata": {
        "id": "ajtkCZfqI5ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
        "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX-uCKCAK1FQ",
        "outputId": "a183356b-34a6-4d30-d618-9490672cec43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기(shape) : (55000, 11)\n",
            "프랑스어 입력데이터의 크기(shape) : (55000, 19)\n",
            "프랑스어 출력데이터의 크기(shape) : (55000, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 언어의 최대 단어갯수에 맞춰 padding을 생성하였다.<br>\n",
        "(`문장의 갯수`,`각 언어의 문장당 단어 최대갯수`)모양의 데이터가 생성되었다.\n"
      ],
      "metadata": {
        "id": "D9kNM2TiK1RF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HbFIKeNV_L8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c844a9-b6ab-47ee-af64-bec6a3137cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[167   8 135   1   0   0   0   0   0   0   0]\n",
            "[  1 243  23 263  18   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0]\n",
            "[243  23 263  18   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0]\n"
          ]
        }
      ],
      "source": [
        "shuffle_idx  = np.arange(MAX_SAMPLE_LEN)\n",
        "np.random.shuffle(shuffle_idx)\n",
        "\n",
        "encoder_input = encoder_input[shuffle_idx]\n",
        "decoder_input = decoder_input[shuffle_idx]\n",
        "decoder_target = decoder_target[shuffle_idx]\n",
        "\n",
        "print(encoder_input[3])\n",
        "print(decoder_input[3])\n",
        "print(decoder_target[3])\n",
        "\n",
        "encoder_input_train = encoder_input[:-VALID_LEN]\n",
        "decoder_input_train = decoder_input[:-VALID_LEN]\n",
        "decoder_target_train = decoder_target[:-VALID_LEN]\n",
        "\n",
        "encoder_input_test = encoder_input[-VALID_LEN:]\n",
        "decoder_input_test = decoder_input[-VALID_LEN:]\n",
        "decoder_target_test = decoder_target[-VALID_LEN:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQlTE3xms-k0"
      },
      "source": [
        "과적합 방지를 위해 학습과 점증을 10:1비율로 나누었다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9puDTo_MRT"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2qbNBHBm0LLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268f24fb-90c3-42bd-98bd-bead2988babd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 64)     408704      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     732800      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 64)     0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, None, 64)     0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 64),         33024       ['masking[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['masking_1[0][0]',              \n",
            "                                 (None, 64),                      'lstm[0][1]',                   \n",
            "                                 (None, 64)]                      'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 11450)  744250      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,951,802\n",
            "Trainable params: 1,951,802\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embadding = Embedding(eng_vocab_size, HIDDEN_STATE_NUM)\n",
        "encoder_masking = Masking(mask_value=0.0)(encoder_embadding(encoder_inputs))\n",
        "encoder_lstm = LSTM(units=HIDDEN_STATE_NUM, return_state = True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_masking)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "decoder_embadding = Embedding(fra_vocab_size, HIDDEN_STATE_NUM)\n",
        "decoder_masking = Masking(mask_value=0.0)(decoder_embadding(decoder_inputs))\n",
        "decoder_lstm = LSTM(units=HIDDEN_STATE_NUM, return_sequences = True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_masking, initial_state = encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "    , loss=\"sparse_categorical_crossentropy\", metrics=['acc']\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encorder는 영어를 프랑스어로 번역하기 위한 레이어이므로<br>영어 최대길이를 input으로 프랑스어 최대길이를 output으로 크기를 설정하였고<br>decorder는 프랑스어가 번역된 것을 검증하기 위한 레이어이므로 입력, 출력 모두 프랑스어에 맞게 설정하였다."
      ],
      "metadata": {
        "id": "yDMdVE5Grafh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_kwargs[\"validation_data\"] = ([encoder_input_test, decoder_input_test], decoder_target_test)\n",
        "\n",
        "history_dict = model.fit(\n",
        "                         x=[encoder_input_train, decoder_input_train]\n",
        "                         , y=decoder_target_train\n",
        "                         , **fit_kwargs).history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epoch = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epoch, loss, 'bo', label='Training loss')\n",
        "plt.plot(epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hy1iw1_slsf3",
        "outputId": "b65c2b33-c875-4698-a019-475cb7f47987"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 25s 20ms/step - loss: 1.6433 - acc: 0.7518 - val_loss: 1.1644 - val_acc: 0.8089\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.0146 - acc: 0.8281 - val_loss: 0.9390 - val_acc: 0.8403\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.8162 - acc: 0.8506 - val_loss: 0.8166 - val_acc: 0.8542\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6874 - acc: 0.8649 - val_loss: 0.7505 - val_acc: 0.8628\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5968 - acc: 0.8752 - val_loss: 0.7116 - val_acc: 0.8680\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5280 - acc: 0.8838 - val_loss: 0.6829 - val_acc: 0.8719\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4729 - acc: 0.8914 - val_loss: 0.6636 - val_acc: 0.8753\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4276 - acc: 0.8980 - val_loss: 0.6543 - val_acc: 0.8784\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.3903 - acc: 0.9041 - val_loss: 0.6458 - val_acc: 0.8798\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.3595 - acc: 0.9090 - val_loss: 0.6450 - val_acc: 0.8812\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.3331 - acc: 0.9139 - val_loss: 0.6457 - val_acc: 0.8833\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.3118 - acc: 0.9177 - val_loss: 0.6447 - val_acc: 0.8849\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2927 - acc: 0.9216 - val_loss: 0.6475 - val_acc: 0.8853\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2775 - acc: 0.9248 - val_loss: 0.6540 - val_acc: 0.8858\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2641 - acc: 0.9275 - val_loss: 0.6563 - val_acc: 0.8863\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2530 - acc: 0.9299 - val_loss: 0.6641 - val_acc: 0.8855\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.2427 - acc: 0.9321 - val_loss: 0.6679 - val_acc: 0.8865\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2337 - acc: 0.9340 - val_loss: 0.6753 - val_acc: 0.8869\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2260 - acc: 0.9353 - val_loss: 0.6799 - val_acc: 0.8859\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.2190 - acc: 0.9371 - val_loss: 0.6869 - val_acc: 0.8870\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2125 - acc: 0.9384 - val_loss: 0.6966 - val_acc: 0.8857\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2086 - acc: 0.9389 - val_loss: 0.7014 - val_acc: 0.8860\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2025 - acc: 0.9404 - val_loss: 0.7117 - val_acc: 0.8863\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1992 - acc: 0.9412 - val_loss: 0.7091 - val_acc: 0.8872\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1935 - acc: 0.9422 - val_loss: 0.7174 - val_acc: 0.8866\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1907 - acc: 0.9429 - val_loss: 0.7224 - val_acc: 0.8873\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1871 - acc: 0.9436 - val_loss: 0.7301 - val_acc: 0.8877\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1832 - acc: 0.9443 - val_loss: 0.7341 - val_acc: 0.8859\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1810 - acc: 0.9447 - val_loss: 0.7433 - val_acc: 0.8863\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1787 - acc: 0.9453 - val_loss: 0.7434 - val_acc: 0.8865\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1752 - acc: 0.9464 - val_loss: 0.7518 - val_acc: 0.8858\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1733 - acc: 0.9465 - val_loss: 0.7556 - val_acc: 0.8856\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1708 - acc: 0.9473 - val_loss: 0.7590 - val_acc: 0.8859\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1703 - acc: 0.9468 - val_loss: 0.7664 - val_acc: 0.8869\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1662 - acc: 0.9481 - val_loss: 0.7729 - val_acc: 0.8863\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1650 - acc: 0.9483 - val_loss: 0.7782 - val_acc: 0.8857\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1634 - acc: 0.9488 - val_loss: 0.7835 - val_acc: 0.8853\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1617 - acc: 0.9489 - val_loss: 0.7865 - val_acc: 0.8862\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1601 - acc: 0.9493 - val_loss: 0.7886 - val_acc: 0.8863\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1596 - acc: 0.9493 - val_loss: 0.7936 - val_acc: 0.8847\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1576 - acc: 0.9499 - val_loss: 0.7975 - val_acc: 0.8846\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1564 - acc: 0.9501 - val_loss: 0.8032 - val_acc: 0.8851\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.1554 - acc: 0.9503 - val_loss: 0.8060 - val_acc: 0.8853\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.1535 - acc: 0.9506 - val_loss: 0.8081 - val_acc: 0.8856\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1528 - acc: 0.9509 - val_loss: 0.8156 - val_acc: 0.8850\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1519 - acc: 0.9508 - val_loss: 0.8205 - val_acc: 0.8847\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1507 - acc: 0.9513 - val_loss: 0.8245 - val_acc: 0.8855\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1499 - acc: 0.9515 - val_loss: 0.8305 - val_acc: 0.8842\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1497 - acc: 0.9513 - val_loss: 0.8293 - val_acc: 0.8852\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.1477 - acc: 0.9518 - val_loss: 0.8320 - val_acc: 0.8862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU5bn38e/NsDmyw6gIzAxGFkH2AVTU4HLegHpwiSYiRyWoCPHELUdFSQLRw3slJ568HhM1B41iIoomJgS3aFzRqFEgBAUhQWUZN2AIm4Cy3O8fTzXTM0zPAlPdM92/z3XV1d3V1dV3zVJ3PUs9j7k7IiKSu5pkOgAREcksJQIRkRynRCAikuOUCEREcpwSgYhIjlMiEBHJcUoEUq/M7Bkzu7S+t80kM1tlZqfHsF83s6Oj578ws+/XZtsD+J5xZvbcgcZZzX5Hmllpfe9X0q9ppgOQzDOzbUkv84EvgD3R6yvdfXZt9+Xuo+PYNtu5+6T62I+ZFQMfAs3cfXe079lArX+HknuUCAR3b5V4bmargMvd/fnK25lZ08TJRUSyh6qGJKVE0d/MbjKzT4EHzKy9mT1pZuvN7J/R865Jn3nZzC6Pno83s9fM7PZo2w/NbPQBbtvdzOab2VYze97M7jKzh1LEXZsYbzOzP0f7e87MOiW9f7GZrTazMjObWs3PZ7iZfWpmeUnrzjWzJdHzYWb2hpltMrNPzOznZtY8xb5mmdl/Jr2+IfrMx2Y2odK2Z5rZX81si5mtNbPpSW/Pjx43mdk2Mzs+8bNN+vwJZva2mW2OHk+o7c+mOmZ2TPT5TWa21MzGJL13hpkti/b5kZn9R7S+U/T72WRmG83sVTPTeSnN9AOXmhwBdACKgImEv5kHoteFwA7g59V8fjiwAugE/BfwSzOzA9j2YeAtoCMwHbi4mu+sTYwXAd8CDgOaA4kTUx/gnmj/R0bf15UquPtfgM+BUyvt9+Ho+R7guuh4jgdOA75dTdxEMYyK4vkXoAdQuX3ic+ASoB1wJjDZzM6J3js5emzn7q3c/Y1K++4APAXcGR3bT4GnzKxjpWPY72dTQ8zNgCeA56LPfQeYbWa9ok1+SahmbA0cC7wYrf8uUAoUAIcDtwAa9ybNlAikJnuBae7+hbvvcPcyd3/c3be7+1ZgBvDVaj6/2t3vdfc9wINAZ8I/fK23NbNCYCjwA3f/0t1fA+al+sJaxviAu//d3XcAjwEDo/XnA0+6+3x3/wL4fvQzSOURYCyAmbUGzojW4e4L3f1Nd9/t7quA/60ijqp8I4rvXXf/nJD4ko/vZXd/x933uvuS6Ptqs18IieMf7v7rKK5HgOXAvyZtk+pnU53jgFbAj6Lf0YvAk0Q/G2AX0MfM2rj7P919UdL6zkCRu+9y91ddA6ClnRKB1GS9u+9MvDCzfDP736jqZAuhKqJdcvVIJZ8mnrj79uhpqzpueySwMWkdwNpUAdcyxk+Tnm9PiunI5H1HJ+KyVN9FuPo/z8xaAOcBi9x9dRRHz6ja49Mojv9LKB3UpEIMwOpKxzfczF6Kqr42A5Nqud/EvldXWrca6JL0OtXPpsaY3T05aSbv9+uEJLnazF4xs+Oj9T8BVgLPmdkHZjaldoch9UmJQGpS+ersu0AvYLi7t6G8KiJVdU99+AToYGb5Seu6VbP9wcT4SfK+o+/smGpjd19GOOGNpmK1EIQqpuVAjyiOWw4kBkL1VrKHCSWibu7eFvhF0n5rupr+mFBllqwQ+KgWcdW0326V6vf37dfd33b3swnVRnMJJQ3cfau7f9fdjwLGANeb2WkHGYvUkRKB1FVrQp37pqi+eVrcXxhdYS8ApptZ8+hq8l+r+cjBxPhb4CwzOzFq2L2Vmv9PHgauISSc31SKYwuwzcx6A5NrGcNjwHgz6xMlosrxtyaUkHaa2TBCAkpYT6jKOirFvp8GeprZRWbW1My+CfQhVOMcjL8QSg83mlkzMxtJ+B3NiX5n48ysrbvvIvxM9gKY2VlmdnTUFrSZ0K5SXVWcxECJQOrqDuAQYAPwJvDHNH3vOEKDaxnwn8CjhPsdqnLAMbr7UuAqwsn9E+CfhMbM6iTq6F909w1J6/+DcJLeCtwbxVybGJ6JjuFFQrXJi5U2+TZwq5ltBX5AdHUdfXY7oU3kz1FPnOMq7bsMOItQaioDbgTOqhR3nbn7l4QT/2jCz/1u4BJ3Xx5tcjGwKqoim0T4fUJoDH8e2Aa8Adzt7i8dTCxSd6Z2GWmMzOxRYLm7x14iEcl2KhFIo2BmQ83sK2bWJOpeeTahrllEDpLuLJbG4gjgd4SG21Jgsrv/NbMhiWQHVQ2JiOQ4VQ2JiOS4Rlc11KlTJy8uLs50GCIijcrChQs3uHtBVe81ukRQXFzMggULMh2GiEijYmaV7yjfR1VDIiI5TolARCTHKRGIiOS4RtdGICLpt2vXLkpLS9m5c2fNG0tGtWzZkq5du9KsWbNaf0aJQERqVFpaSuvWrSkuLib1vEKSae5OWVkZpaWldO/evdafy4mqodmzobgYmjQJj7M1jbdInezcuZOOHTsqCTRwZkbHjh3rXHLL+hLB7NkwcSJsj6Y0Wb06vAYYNy7150SkIiWBxuFAfk9ZXyKYOrU8CSRs3x7Wi4hIDiSCNWvqtl5EGp6ysjIGDhzIwIEDOeKII+jSpcu+119++WW1n12wYAFXX311jd9xwgkn1EusL7/8MmeddVa97Ctdsj4RFFae5K+G9SJy8Oq7Xa5jx44sXryYxYsXM2nSJK677rp9r5s3b87u3btTfrakpIQ777yzxu94/fXXDy7IRizrE8GMGZCfX3Fdfn5YLyL1L9Eut3o1uJe3y9V3J43x48czadIkhg8fzo033shbb73F8ccfz6BBgzjhhBNYsWIFUPEKffr06UyYMIGRI0dy1FFHVUgQrVq12rf9yJEjOf/88+nduzfjxo0jMUrz008/Te/evRkyZAhXX311jVf+Gzdu5JxzzqF///4cd9xxLFmyBIBXXnllX4lm0KBBbN26lU8++YSTTz6ZgQMHcuyxx/Lqq6/W7w+sGrE1FpvZ/YQp8da5+7EpthlJmJKvGbDB3b9a33EkGoSnTg3VQYWFIQmooVgkHtW1y9X3/11paSmvv/46eXl5bNmyhVdffZWmTZvy/PPPc8stt/D444/v95nly5fz0ksvsXXrVnr16sXkyZP363P/17/+laVLl3LkkUcyYsQI/vznP1NSUsKVV17J/Pnz6d69O2PHjq0xvmnTpjFo0CDmzp3Liy++yCWXXMLixYu5/fbbueuuuxgxYgTbtm2jZcuWzJw5k6997WtMnTqVPXv2sL3yDzFGcfYamgX8HPhVVW+aWTvCvKaj3H2NmR0WVyDjxunEL5Iu6WyXu+CCC8jLywNg8+bNXHrppfzjH//AzNi1a1eVnznzzDNp0aIFLVq04LDDDuOzzz6ja9euFbYZNmzYvnUDBw5k1apVtGrViqOOOmpf//yxY8cyc+bMauN77bXX9iWjU089lbKyMrZs2cKIESO4/vrrGTduHOeddx5du3Zl6NChTJgwgV27dnHOOecwcODAg/rZ1EVsVUPuPh/YWM0mFwG/c/c10fbr4opFRNInne1yhx566L7n3//+9znllFN49913eeKJJ1L2pW/RosW+53l5eVW2L9Rmm4MxZcoU7rvvPnbs2MGIESNYvnw5J598MvPnz6dLly6MHz+eX/2qymvoWGSyjaAn0N7MXjazhWZ2SaoNzWyimS0wswXr169PY4giUleZapfbvHkzXbp0AWDWrFn1vv9evXrxwQcfsGrVKgAeffTRGj9z0kknMTtqHHn55Zfp1KkTbdq04f3336dfv37cdNNNDB06lOXLl7N69WoOP/xwrrjiCi6//HIWLVpU78eQSiYTQVNgCHAm8DXg+2bWs6oN3X2mu5e4e0lBQZXzKohIAzFuHMycCUVFYBYeZ86Mv3r2xhtv5Oabb2bQoEH1fgUPcMghh3D33XczatQohgwZQuvWrWnbtm21n5k+fToLFy6kf//+TJkyhQcffBCAO+64g2OPPZb+/fvTrFkzRo8ezcsvv8yAAQMYNGgQjz76KNdcc029H0Mqsc5ZbGbFwJNVNRab2RTgEHefFr3+JfBHd/9NdfssKSlxTUwjkl7vvfcexxxzTKbDyLht27bRqlUr3J2rrrqKHj16cN1112U6rP1U9fsys4XuXlLV9pksEfwBONHMmppZPjAceC+D8YiIVOvee+9l4MCB9O3bl82bN3PllVdmOqR6EWf30UeAkUAnMysFphG6ieLuv3D398zsj8ASYC9wn7u/G1c8IiIH67rrrmuQJYCDFVsicPcaO9m6+0+An8QVg4iI1Czr7ywWEZHqKRGIiOQ4JQIRkRynRCAiDd4pp5zCs88+W2HdHXfcweTJk1N+ZuTIkSS6mp9xxhls2rRpv22mT5/O7bffXu13z507l2XLlu17/YMf/IDnn3++LuFXqSENV61EICIN3tixY5kzZ06FdXPmzKnVwG8QRg1t167dAX135URw6623cvrppx/QvhoqJQIRafDOP/98nnrqqX2T0KxatYqPP/6Yk046icmTJ1NSUkLfvn2ZNm1alZ8vLi5mw4YNAMyYMYOePXty4okn7huqGsI9AkOHDmXAgAF8/etfZ/v27bz++uvMmzePG264gYEDB/L+++8zfvx4fvvb3wLwwgsvMGjQIPr168eECRP44osv9n3ftGnTGDx4MP369WP58uXVHl+mh6vO+jmLRaR+XXstLF5cv/scOBDuuCP1+x06dGDYsGE888wznH322cyZM4dvfOMbmBkzZsygQ4cO7Nmzh9NOO40lS5bQv3//KvezcOFC5syZw+LFi9m9ezeDBw9myJAhAJx33nlcccUVAHzve9/jl7/8Jd/5zncYM2YMZ511Fueff36Ffe3cuZPx48fzwgsv0LNnTy655BLuuecerr32WgA6derEokWLuPvuu7n99tu57777Uh5fpoerVolARBqF5Oqh5Gqhxx57jMGDBzNo0CCWLl1aoRqnsldffZVzzz2X/Px82rRpw5gxY/a99+6773LSSSfRr18/Zs+ezdKlS6uNZ8WKFXTv3p2ePcMQaZdeeinz58/f9/55550HwJAhQ/YNVJfKa6+9xsUXXwxUPVz1nXfeyaZNm2jatClDhw7lgQceYPr06bzzzju0bt262n3XhkoEIlIn1V25x+nss8/muuuuY9GiRWzfvp0hQ4bw4Ycfcvvtt/P222/Tvn17xo8fn3L46ZqMHz+euXPnMmDAAGbNmsXLL798UPEmhrI+mGGsp0yZwplnnsnTTz/NiBEjePbZZ/cNV/3UU08xfvx4rr/+ei65JOXgzbWiEoGINAqtWrXilFNOYcKECftKA1u2bOHQQw+lbdu2fPbZZzzzzDPV7uPkk09m7ty57Nixg61bt/LEE0/se2/r1q107tyZXbt27Rs6GqB169Zs3bp1v3316tWLVatWsXLlSgB+/etf89WvHtgki5kerlolAhFpNMaOHcu55567r4ooMWxz79696datGyNGjKj284MHD+ab3/wmAwYM4LDDDmPo0KH73rvtttsYPnw4BQUFDB8+fN/J/8ILL+SKK67gzjvv3NdIDNCyZUseeOABLrjgAnbv3s3QoUOZNGnSAR1XYi7l/v37k5+fX2G46pdeeokmTZrQt29fRo8ezZw5c/jJT35Cs2bNaNWqVb1MYBPrMNRx0DDUIumnYagbl8Y0DLWIiDQASgQiIjlOiUBEaqWxVSPnqgP5PSkRiEiNWrZsSVlZmZJBA+fulJWV0bJlyzp9Tr2GRKRGXbt2pbS0lPXr12c6FKlBy5Yt6dq1a50+E+dUlfcDZwHrqpq8Pmm7ocAbwIXu/ttU24lI5jRr1ozu3btnOgyJSZxVQ7OAUdVtYGZ5wI+B52KMQ0REqhFbInD3+cDGGjb7DvA4sC6uOEREpHoZayw2sy7AucA9tdh2opktMLMFqqMUEalfmew1dAdwk7vvrWlDd5/p7iXuXlJQUJCG0EREckcmew2VAHPMDKATcIaZ7Xb3uRmMSUQk52QsEbj7vi4IZjYLeFJJQEQk/eLsPvoIMBLoZGalwDSgGYC7/yKu7xURkbqJLRG4e+1mlQ7bjo8rDhERqZ6GmBARyXFKBCIiOU6JQEQkxykRiIjkOCUCEZEcp0QgIpLjlAhERHKcEoGISI5TIhARyXFKBCIiOU6JQEQkxykRiIjkOCUCEZEcp0QgIpLjlAhERHKcEoGISI5TIhARyXFKBCIiOS62RGBm95vZOjN7N8X748xsiZm9Y2avm9mAuGIREZHU4iwRzAJGVfP+h8BX3b0fcBswM8ZYREQkhTgnr59vZsXVvP960ss3ga5xxSIiIqk1lDaCy4BnUr1pZhPNbIGZLVi/fn0awxIRyX4ZTwRmdgohEdyUaht3n+nuJe5eUlBQkL7gRERyQGxVQ7VhZv2B+4DR7l6WyVhERHJVxkoEZlYI/A642N3/Hvf3bdsGL70Eu3fH/U0iIo1LnN1HHwHeAHqZWamZXWZmk8xsUrTJD4COwN1mttjMFsQVC8DcuXDqqfDee3F+i4hI4xNnr6GxNbx/OXB5XN9f2bBh4fGtt6Bfv3R9q4hIw5fxxuJ0OfpoaNsW3n4705GIiDQsOZMImjSBkpJQIhARkXI5kwggVA+98w7s3JnpSEREGo6cSgRDh4ZeQ4sXZzoSEZGGI+cSAah6SEQkWU4lgi5doHNnNRiLiCTLqURgFkoFSgQiIuVyKhFAaDBesQI2bcp0JCIiDUPOJYJEO8HChZmNQ0Skoci5RFBSEh5VPSQiEuRcIujQIdxlrJ5DIiJBziUCUIOxiEiynE0EpaXwySeZjkREJPNyMhEkRiJVqUBEJEcTwaBBkJenRCAiAjmaCPLzoW/f0GA8ezYUF4fRSYuLw2sRkVyS0TmLM2nYMJgzB159FXbsCOtWr4aJE8PzceMyF5uISDrFOVXl/Wa2zszeTfG+mdmdZrbSzJaY2eC4YqnK0KFhHuNEEkjYvh2mTk1nJCIimRVn1dAsYFQ1748GekTLROCeGGPZT+IO46qsWZO+OEREMi22RODu84GN1WxyNvArD94E2plZ57jiqezYY8MgdFUpLExXFCIimZfJxuIuwNqk16XRuv2Y2UQzW2BmC9avX18vX96sWbjDuEmln0B+PsyYUS9fISLSKDSKXkPuPtPdS9y9pKCgoN72e8YZ0LRpKAGYQVERzJyphmIRyS2ZTAQfAd2SXneN1qXN0KHw5ZfwxBOwdy+sWqUkICK5J5OJYB5wSdR76Dhgs7unddCHRIOxbiwTkVwWZ/fRR4A3gF5mVmpml5nZJDObFG3yNPABsBK4F/h2XLGkcvTR0K6dRiIVkdwW2w1l7j62hvcduCqu76+NJk3C/AQqEYhILqtVicDMDjWzJtHznmY2xsyaxRtaegwdCkuW7H9jmYhIrqht1dB8oKWZdQGeAy4m3DDW6A0bBnv2wOLFmY5ERCQzapsIzN23A+cBd7v7BUDf+MJKn+OOC11Hn30205GIiGRGrROBmR0PjAOeitblxRNSeh1xBJx+OsyaFbqQiojkmtomgmuBm4Hfu/tSMzsKeCm+sNJrwoQw8uiLL2Y6EhGR9KtVryF3fwV4BSBqNN7g7lfHGVg6nXMOtG8P998fSgciIrmktr2GHjazNmZ2KPAusMzMbog3tPRp2TLcUfy738E//5npaERE0qu2VUN93H0LcA7wDNCd0HMoa0yYAF98AQ8/nOlIRETSq7aJoFl038A5wDx33wV4fGGl36BBMHBgqB4SEckltU0E/wusAg4F5ptZEbAlrqAy5bLLYNEi3VMgIrmlVonA3e909y7ufkY0kcxq4JSYY0u7iy6C5s1VKhCR3FLbxuK2ZvbTxOQwZvbfhNJBVunQAc49Fx56CHbuzHQ0IiLpUduqofuBrcA3omUL8EBcQWXSZZeFnkN/+EOmIxERSY/aJoKvuPs0d/8gWn4IHBVnYJly6qlhxjJVD4lIrqhtIthhZicmXpjZCCArx+vMy4Px4+FPf4I1azIdjYhI/GqbCCYBd5nZKjNbBfwcuDK2qDLsW98C9zD+kIhIfdu7FzZuhC1bwv1Llcc5c4ft2+GTT2DFijB51vPPh+dxsDA/TC03NmsTgvQtZnatu98RT1iplZSU+IIFC2L/nmOPheXLwxDVRUUwY4bmMxaRmrmHdsZ168Ly0UdhPvQPPyx/XLMmzJeerGlTaNEiPH7+Oezevf++b7wRfvzjA4vLzBa6e0lV79VphrLo7uKE64G0J4J0mD0b/vGPkAQgDEg3cWJ4rmQgkpvcw4l97Vr4+ONwgk9+/PTT8P769VWfxAsKoLgYBg+G886Dzp3DOebLL8PyxRfhcdcuaNUK2rSBtm3LH9u2DZ+PQ51KBBU+aLbW3bvVsM0o4H8IQ1bf5+4/qvR+IfAg0C7aZoq7P13dPtNRIiguDif/yoqKQkYXkezjHmYq/Pxz2LQJ/v53eO+9isumTRU/06RJGMq+Sxc4/PCwHHZYxaVz53BOOTTDHe7rrURQSbUZxMzygLuAfwFKgbfNbJ67L0va7HvAY+5+j5n1IUxoX3wQMdWLVI3EajwWaRy2bQsXc4nls8/CSXzTJti8ufz5li1h288/D3XyVV0XH344HHMMXHgh9O4dTupdusCRR4b38rJgZpZqE4GZbaXqE74Bh9Sw72HASnf/INrXHOBsIDkRONAmet4W+LgWMceusLDqEkFhYfpjEZFg795Q7fLRR+VVMInHxLJ2bbhg27hx/8+3bg3t2oWlbVvo2jVUu7RqFa7WE4+HHhrWH310SADt26f/WNOt2kTg7q0PYt9dgLVJr0uB4ZW2mQ48Z2bfIdypXOVsAGY2EZgIUJiGs/GMGaFNYPv25Bjg+9+P/atFslqi+mXTptCgmrhCT1yVJ5Zt28LVeqIO/qOPQg+aXbv232ezZqH+vaAgXKkff3yoxi0sDI9FRaH6Jhuu3ONyMFVD9WEsMMvd/zuaCvPXZnasu1foTOXuM4GZENoI4g4q0SA8dWq4ujjssHDl8Ze/hDuPRWR/27dDaWm4Kl+7dv/nieqZyr1lqmIWruA7dw4n969+NTwmlkRdfEFBuHo3i//4slmcieAjILkxuWu0LtllwCgAd3/DzFoCnYB1McZVK+PGVewhdPPN8KMfwejRYTwikVyzeTO8/35YPvggXCQlTvRr10JZ2f6fKSiAbt2ge3c47rhQzdK+faieSTy2bbt/9cwhh+jknk5xJoK3gR5m1p2QAC4ELqq0zRrgNGCWmR0DtATWxxjTAfvhD8PdxpdfDsOHh4YikWyzcyesXBl6yCxfHm5gWrkynPw3bKi4bfv24STfrVs4ySeeJ5YuXcLsf9LwxZYI3H23mf078Cyha+j90cT3twIL3H0e8F3gXjO7jtBwPN4PtD9rzJo3D/cXDB4chqD44x9D1zGRhm7v3lAfv359OJlv3Biu3hOPZWWhDn758nCzU/JdroWFodH0vPPgK18Jy9FHw1FHhaobyQ4HfB9BpqTrzuJU7r03NCT/6Edw000ZC0NkH/dQNfPOO7BkSXj8+OPynjRlZfsPYZDQtGkYfv2II0LXyMRyzDHQsyfk56f3WCQ+cd1HkJMuvxyeew6mTAlXWTNmqDeC1L8dO8JJfdGiine5u5f3df/ii3AVv2RJqL9PSPSY6d0bTjop1NN36lT+2LFjOPl37Biu6lUXL0oEdWQWJrgvKAhjfixdGqqM2rSp+bMiybZvr9gf/v33w4l/4cJQR584+efnhy6SiRN24rFp03DVftFF0L8/9OsXxshq2zYzxyONlxLBAWjWDO6+O/zTXX01nHACzJsX6k1FEtxDFc2yZeHEvmxZWEpLw4n/88/3/8zhh8OQIXDOOeFx8ODQ8KqrdomTEsFB+Pa3oVcvuOACGDYMHn889HeW3LB7dxh7au3a8pueSkvLH1esCDdFJbRvD337hguH5DFpCgrCY7duod+8SLopERyk004LN5qNGQOnnw4/+xlceaWu4BqbTZvCmO/r1oVqvsrLnj3w7rsVG2SXLdt/buu2bctverr4YujTJzS89ukTTvb6u5CGSImgHvToAW++GQalmjwZHnssVB317p3pyKQqe/aEtp033yxf3nuv9p/v3DnUx191VageLCwM49YceWS4IUqksVEiqKPZs8uHnigsLJ+wpm1bePLJ0L305ptD490NN4Rt1QUvvfbsCb1pFi0Kv6ePP664fPpp+XjxnTqFm6HGjSu/KWrr1lClk7y4h2qdfv3CZ0Syie4jqIPZs/cfjC4/H2bOrDgcxWefhZmEfvWrMGTtz34GZ52V9nBzwt694SaoBQvg7bfDsnBhxYbYDh3C1Xpi6dw5VNUcf3xo4Fd1jeSC6u4jUCKog7pOWPPKK6FBedmy0IZwyy2hUVknnrrZtSsk1zVrwmQhiSUx/EGinr5FCxg4EIYODUtJSTjRa5gDESWCetOkSdUTV5ilvnPzyy/hjjvgttvC0LqDBoV2hIsuyvyMRQ3F9u3hxL58eairX706DDmcWCqPcdO0aRjqoGfP0GurV6/Q1fLYY0PXXhHZnxJBPTmYKSy3bAlVS/fcE3qctGkTepVMnhzqnrNVWVmok9+woeIEIuvXh6v55cvDzzTxZ9ikSehx07lzGPagc+fypWvXcPIvLg7JQERqT4mgntS2jaA67vD66yEh/OY3ocTQtWu4ok0sgweHk2BjsWtXONEn3zS1dGl4rHw1n9CuXRiaODGuTWKMmx49VJUjEgclgnqUqtfQgdiwAR55JHRfXLgwVI8kfh1HHhmqkfr3D8uAAeEkma4r4T17wo1SiSGI338/PP/441DFtW1b6F2zbdv+E420bRtKOX37hpP8kUeWzyDVqVNYVIUjkl5KBI3E1q2weHFICgsXwt/+Fq6yE10dW7YMJ9fi4nAibdYsJIbEY15eOIHv3l1x2bu3fLvmzcOS+Pz27ftP6L1p0/7TArZoERpek+d5TV7atQtX9H36hGocNYiLNCwafXZXU3AAAA0TSURBVLSRaN06jBZ50knl6778MiSDJUvCkpwcdu0KS+L5nj3hhJ+85OWFZffusK9du8Jj4nl+fvksUe3ahSTTrl2omurRo3z8+S5dNP+CSLZSImjgmjcP1UIDBmQ6EhHJVrrGExHJcbEmAjMbZWYrzGylmU1Jsc03zGyZmS01s4fjjEdERPYXWyIwszzgLmA00AcYa2Z9Km3TA7gZGOHufYFr44onbrNnh/r1Jk3C4+zZmY5IRKR24mwjGAasdPcPAMxsDnA2sCxpmyuAu9z9nwDuvi7GeGJT+f6C1avDazjwrqUiIukSZ9VQF2Bt0uvSaF2ynkBPM/uzmb1pZqOq2pGZTTSzBWa2YP369TGFe+CmTq14kxmE11OnZiYeEZG6yHRjcVOgBzASGAvca2btKm/k7jPdvcTdSwoKCtIcYs3WrKnbehGRhiTORPAR0C3pdddoXbJSYJ6773L3D4G/ExJDo1JYWLf1IiINSZyJ4G2gh5l1N7PmwIXAvErbzCWUBjCzToSqog9ijCkWM2bsP/lMfn5YLyLS0MWWCNx9N/DvwLPAe8Bj7r7UzG41szHRZs8CZWa2DHgJuMHdy+KKKS7jxoWB54qKwtAKRUV1G4hORCSTNNaQiEgOqG6soUw3FouISIYpEcRMN5qJSEOnQedipBvNRKQxUIkgRrrRTEQaAyWCGOlGMxFpDJQIYqQbzUSkMVAiiJFuNBORxkCJIEa60UxEGgMlgpiNGwerVoUJ5FetqpgE1LVURBoCdR/NEHUtFZGGQiWCDFHXUhFpKJQIMkRdS0WkoVAiyBB1LRWRhkKJIEPUtVREGgolggyprmupehOJSDqp11AGjRu3fw8h9SYSkXRTiaCBUW8iEUm3WBOBmY0ysxVmttLMplSz3dfNzM2sytlzcol6E4lIusWWCMwsD7gLGA30AcaaWZ8qtmsNXAP8Ja5YGhP1JhKRdIuzRDAMWOnuH7j7l8Ac4OwqtrsN+DGwM8ZYGo3qehOpEVlE4hBnIugCrE16XRqt28fMBgPd3P2pGONoVFL1JoLQaLx6NbiXNyIrGYjIwcpYryEzawL8FBhfi20nAhMBCnOgjqSq3kTFxakbkdWbSEQORpwlgo+Abkmvu0brEloDxwIvm9kq4DhgXlUNxu4+091L3L2koKAgxpAbLjUii0hc4kwEbwM9zKy7mTUHLgTmJd50983u3sndi929GHgTGOPuC2KMqdGqrhFZbQcicjBiSwTuvhv4d+BZ4D3gMXdfama3mtmYuL43W6VqRD7jDLUdiMjBMXfPdAx1UlJS4gsW5GahYfbs0CawZk0oCcyYEV6vXr3/tkVFYSIcEREAM1vo7lXeq6U7ixuRqmY7q6ntQNVGIlITJYJGrqa2A1UbiUhNlAgauepuQNO4RSJSG0oEjVx1w1lXV22kKiMRSVBjcRYrLq66IbljR9ixo2JpIT+/PIGISPZRY3GOSlVtBKoyEpFySgRZLFW10caNVW+vKiOR3KSqoRykKiOR3KOqIangQKqMVFIQyV5KBDmorlVGifsPdD+CSHZSIshRVd2lnOrmtLw8lRREspkSgeyTqspoz56qt6+ppKAkIdI4KBHIPqmqjIqKqt6+ppJCqiShBCHSsKjXkNQocVKv3JuochJIMAvVTOqZJNJwqNeQHJS6lhQKC1MPb1FWpvYGkYZGiUBqparG5eoGvKvr1NLVtTekShBKHCL1xN0b1TJkyBCXhuOhh9yLitzNwuNDD5Wvz893D6f1sOTnu3fsWHFdYsnLq3p9x45V72fy5KrXJ39/VXGJ5Cpggac4r6qNQGJT1YxqULf2hlTy8qruzVRUFL6nqu+YOTM8rxyT2iYkF1TXRhDr1TswClgBrASmVPH+9cAyYAnwAlBU0z5VImj8qrpaLyqqukRQ1yWxz7qULh56qPqSjUoWkg2opkQQZxLIA94HjgKaA38D+lTa5hQgP3o+GXi0pv0qEWSn+qpKSpy065I8DqT6qboEoeQhDVGmEsHxwLNJr28Gbq5m+0HAn2varxJB9qrqBJoqQVR3kq6v0kVd2y2qi1elDsm0TCWC84H7kl5fDPy8mu1/DnwvxXsTgQXAgsLCwth+UNIw1fUEWtfSRX0tRUV1r5aq71KHkoqk0uATAfBvwJtAi5r2qxKB1EZdShd1rX5KtZjVvVqqPksdB5JUDiShKNk0Tg26agg4HXgPOKw2+1UikINRH9VPqRJHdSWCdJQ66qsLbk0JJe5koyQUj0wlgqbAB0D3pMbivpW2GRQ1KPeo7X6VCCQOdTkp1XQybGiljrqWRqpriK+vqq+GmoQO5DONJTllJBGE7+UM4O/RyX5qtO5WYEz0/HngM2BxtMyraZ9KBNIQ1PVEko5SR12TSl2X+qz6aohJ6EB+T/VZHVfde/WRbDKWCOJYlAiksYq71FHXpFKfJ+O4l3QkoQNJsvV5R/yBtP3UhRKBSCNUX1eO9X2VG2eyyWQSqs9qt7ompwNJQkVFdft7UiIQyXFx16HXV7LJZBKqzxJBOpKQWd3+BpQIRCR2meo1lI4ST133dSB3xKtEoEQgIgehofUaOtB7PdRGoEQgIlmkMfUa0jDUIiI5QFNViohISkoEIiI5TolARCTHKRGIiOQ4JQIRkRzX6HoNmdl6YHUNm3UCNqQhnIZGx517cvXYddx1V+TuBVW90egSQW2Y2YJU3aSymY479+Tqseu465eqhkREcpwSgYhIjsvWRDAz0wFkiI479+Tqseu461FWthGIiEjtZWuJQEREakmJQEQkx2VdIjCzUWa2wsxWmtmUTMcTFzO738zWmdm7Ses6mNmfzOwf0WP7TMYYBzPrZmYvmdkyM1tqZtdE67P62M2spZm9ZWZ/i477h9H67mb2l+jv/VEza57pWONgZnlm9lczezJ6nfXHbWarzOwdM1tsZguidbH8nWdVIjCzPOAuYDTQBxhrZn0yG1VsZgGjKq2bArzg7j2AF6LX2WY38F137wMcB1wV/Y6z/di/AE519wHAQGCUmR0H/Bj4f+5+NPBP4LIMxhina4D3kl7nynGf4u4Dk+4diOXvPKsSATAMWOnuH7j7l8Ac4OwMxxQLd58PbKy0+mzgwej5g8A5aQ0qDdz9E3dfFD3fSjg5dCHLjz2aW2Rb9LJZtDhwKvDbaH3WHTeAmXUFzgTui14bOXDcKcTyd55tiaALsDbpdWm0Llcc7u6fRM8/BQ7PZDBxM7NiYBDwF3Lg2KPqkcXAOuBPwPvAJnffHW2SrX/vdwA3Anuj1x3JjeN24DkzW2hmE6N1sfydN62PnUjD4+5uZlnbN9jMWgGPA9e6+5ZwkRhk67G7+x5goJm1A34P9M5wSLEzs7OAde6+0MxGZjqeNDvR3T8ys8OAP5nZ8uQ36/PvPNtKBB8B3ZJed43W5YrPzKwzQPS4LsPxxMLMmhGSwGx3/120OieOHcDdNwEvAccD7cwscUGXjX/vI4AxZraKUNV7KvA/ZP9x4+4fRY/rCIl/GDH9nWdbIngb6BH1KGgOXAjMy3BM6TQPuDR6finwhwzGEouofviXwHvu/tOkt7L62M2sICoJYGaHAP9CaB95CTg/2izrjtvdb3b3ru5eTPh/ftHdx5Hlx21mh5pZ68Rz4P8A7xLT33nW3VlsZmcQ6hTzgPvdfUaGQ4qFmT0CjCQMS/sZMA2YCzwGFBKG6v6Gu1duUG7UzOxE4FXgHcrrjG8htBNk7bGbWX9C42Ae4QLuMXe/1cyOIlwpdwD+Cvybu3+RuUjjE1UN/Ye7n5Xtxx0d3++jl02Bh919hpl1JIa/86xLBCIiUjfZVjUkIiJ1pEQgIpLjlAhERHKcEoGISI5TIhARyXFKBCIRM9sTjfSYWOpt4DozK04eKVakIdEQEyLldrj7wEwHIZJuKhGI1CAaF/6/orHh3zKzo6P1xWb2opktMbMXzKwwWn+4mf0+mjvgb2Z2QrSrPDO7N5pP4LnoDmHM7OpofoUlZjYnQ4cpOUyJQKTcIZWqhr6Z9N5md+8H/Jxw5zrAz4AH3b0/MBu4M1p/J/BKNHfAYGBptL4HcJe79wU2AV+P1k8BBkX7mRTXwYmkojuLRSJmts3dW1WxfhVhUpgPogHvPnX3jma2Aejs7rui9Z+4eyczWw90TR7yIBoy+0/RhCKY2U1AM3f/TzP7I7CNMETI3KR5B0TSQiUCkdrxFM/rInksnD2Ut9GdSZhZbzDwdtKomiJpoUQgUjvfTHp8I3r+OmFETIBxhMHwIEwhOBn2TSbTNtVOzawJ0M3dXwJuAtoC+5VKROKkKw+RcodEM4Al/NHdE11I25vZEsJV/dho3XeAB8zsBmA98K1o/TXATDO7jHDlPxn4hKrlAQ9FycKAO6P5BkTSRm0EIjWI2ghK3H1DpmMRiYOqhkREcpxKBCIiOU4lAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclx/x90mk8jsfGYmwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNQ9W93B0LUx"
      },
      "source": [
        "학습결과 우하향하는 그래프의 모습을 보이며 train loss, validation loss 의 차이가 크지않다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증\n"
      ],
      "metadata": {
        "id": "mv2-aMcEvAs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
        "encoder_model.summary()\n",
        "\n",
        "# 이전 time step의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(HIDDEN_STATE_NUM,))\n",
        "# 이전 time step의 cell state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape=(HIDDEN_STATE_NUM,))\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_embadding_val = decoder_embadding(decoder_inputs)\n",
        "\n",
        "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
        "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
        "decoder_outputs_val, state_h, state_c = decoder_lstm(decoder_embadding_val, initial_state = decoder_states_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
        "decoder_states_val = [state_h, state_c]\n",
        "\n",
        "decoder_outputs_val = decoder_softmax_layer(decoder_outputs_val)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs_val] + decoder_states_val)\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEZRY1YZvA39",
        "outputId": "b640c763-4dba-4086-ba32-6965c2a3b55b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 64)          408704    \n",
            "                                                                 \n",
            " masking (Masking)           (None, None, 64)          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 64),              33024     \n",
            "                              (None, 64),                        \n",
            "                              (None, 64)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 441,728\n",
            "Trainable params: 441,728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     732800      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[1][0]',            \n",
            "                                 (None, 64),                      'input_3[0][0]',                \n",
            "                                 (None, 64)]                      'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 11450)  744250      ['lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,510,074\n",
            "Trainable params: 1,510,074\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6_PrcpfDvBDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "metadata": {
        "id": "m1Soi1Am0_wy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Q_oqPgi0_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = fra2idx[SOS_TOKEN]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += \" \" + sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == EOS_TOKEN or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "wPvlKpzY1B5I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EXgwX_Ff1CEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 10\n",
        "input_seq = encoder_input_train[sample: sample + 1]\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print(\"-\" * 35)\n",
        "\n",
        "print(\"입력문장 :\", \"\".join([\n",
        "        idx2eng[encoded_word] + \" \"\n",
        "        for encoded_word in encoder_input_train[sample]\n",
        "        if encoded_word != 0\n",
        "    ])\n",
        ")\n",
        "print(\"정답문장 :\",  \"\".join([\n",
        "      idx2fra[encoded_word] + \" \"\n",
        "      for encoded_word in decoder_input_train[sample]\n",
        "      if encoded_word != 0 and encoded_word != fra2idx[SOS_TOKEN] and encoded_word != fra2idx[EOS_TOKEN]\n",
        "  ])\n",
        ")\n",
        "\n",
        "print(\"번역문장 :\",decoded_sentence)\n",
        "print(\"-\" * 35)\n",
        "\n",
        "sample = 10\n",
        "input_seq = encoder_input_test[sample: sample + 1]\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print(\"-\" * 35)\n",
        "\n",
        "print(\"입력문장 :\", \"\".join([\n",
        "        idx2eng[encoded_word] + \" \"\n",
        "        for encoded_word in encoder_input_test[sample]\n",
        "        if encoded_word != 0\n",
        "    ])\n",
        ")\n",
        "print(\"정답문장 :\",  \"\".join([\n",
        "      idx2fra[encoded_word] + \" \"\n",
        "      for encoded_word in decoder_input_test[sample]\n",
        "      if encoded_word != 0 and encoded_word != fra2idx[SOS_TOKEN] and encoded_word != fra2idx[EOS_TOKEN]\n",
        "  ])\n",
        ")\n",
        "\n",
        "print(\"번역문장 :\",decoded_sentence)\n",
        "print(\"-\" * 35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5eU9KvT1XZl",
        "outputId": "080dcea4-2934-467d-cb7d-47e6b8c00248"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 360ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-----------------------------------\n",
            "입력문장 : it ' s warmer . \n",
            "정답문장 : c ' est plus chaud . \n",
            "번역문장 :  c ' est plus chaud . <eos>\n",
            "-----------------------------------\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-----------------------------------\n",
            "입력문장 : help me . \n",
            "정답문장 : aide - moi . \n",
            "번역문장 :  aide - moi ! <eos>\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E7-ju2Gp1Xko"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsx8OVYGnM-s"
      },
      "source": [
        "### 회고\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngdabGo3j4l"
      },
      "source": [
        "- 학습된 데이터가 전체적으로 높은 정확도를 보여 미리 학습된 데이터의 중요성을 알게되었다.\n",
        "- 항상 학습된 데이터가 높은 정확도를 나타내는 것이 아니라 하이퍼파라미터의 튜닝에 따라 결과가 달라질 수 있다는 것을 알게 되었다.\n",
        "\n",
        "※ 이번 레포트는 양희성님의 모델구조의 조언으로 작성되었음을 알려드립니다.<br>\n",
        "   희성님에게 감사하다는 글을 남기며 이만 글을 마치겠습니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}